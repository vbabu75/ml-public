{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_psp():\n",
    "    psp = pd.read_csv('price_sales_promotion.csv')\n",
    "    # Drop those with all zeros\n",
    "    psp = psp.drop(psp[(psp.Price==0) & (psp.Sales==0) & (psp.Promotions==0)].index)\n",
    "    # Fix cases where Sales and Price are swapped\n",
    "    faulty_index = psp[(psp.Sales>psp.Price)].index\n",
    "    true_price = psp.loc[faulty_index,'Sales']\n",
    "    true_sales = psp.loc[faulty_index,'Price']\n",
    "    psp.loc[faulty_index,'Price'] = true_price\n",
    "    psp.loc[faulty_index,'Sales'] = true_sales\n",
    "    # Fix cases where Sales is zero and promotions is not\n",
    "    faulty_index = psp[psp.Sales==0].index\n",
    "    true_promotions = psp.loc[faulty_index,'Sales']\n",
    "    true_sales = psp.loc[faulty_index,'Promotions']\n",
    "    psp.loc[faulty_index,'Promotions'] = true_promotions\n",
    "    psp.loc[faulty_index,'Sales'] = true_sales\n",
    "    # Fix cases where Sales and Promotions are swapped\n",
    "    faulty_index = psp[psp.Promotions/psp.Sales>1].index\n",
    "    true_promotions = psp.loc[faulty_index,'Sales']\n",
    "    true_sales = psp.loc[faulty_index,'Promotions']\n",
    "    psp.loc[faulty_index,'Promotions'] = true_promotions\n",
    "    psp.loc[faulty_index,'Sales'] = true_sales    \n",
    "    # Fix individual records\n",
    "    psp.loc[(psp.SKU=='SKU_27')&(psp.YearMonth==201611),'Price'] =1393.936364\n",
    "    psp.loc[(psp.SKU=='SKU_27')&(psp.YearMonth==201611),'Sales'] =1393.936364\n",
    "    psp.loc[(psp.SKU=='SKU_27')&(psp.YearMonth==201612),'Price'] =1916.6625\n",
    "    psp.loc[(psp.SKU=='SKU_27')&(psp.YearMonth==201612),'Sales'] =1916.6625\n",
    "    psp.loc[(psp.SKU=='SKU_17')&(psp.YearMonth==201706),'Promotions'] = 184\n",
    "    psp.loc[(psp.SKU=='SKU_17')&(psp.YearMonth==201706),'Sales'] = 2463.06338-184    \n",
    "    \n",
    "    psp.to_csv('price_sales_promotion_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_hv():\n",
    "    hv = pd.read_csv('historical_volume.csv')\n",
    "    #Drop those with zeros\n",
    "    hv = hv.drop(hv[hv.Volume==0].index)\n",
    "    hv.to_csv('historical_volume_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csvs():\n",
    "    dfs={}\n",
    "    dfs['psp'] = pd.read_csv('price_sales_promotion_cleaned.csv')\n",
    "    dfs['hv'] = pd.read_csv('historical_volume_cleaned.csv')\n",
    "    dfs['wea']= pd.read_csv('weather.csv')\n",
    "    dfs['iss'] = pd.read_csv('industry_soda_sales.csv')\n",
    "    dfs['ec'] = pd.read_csv('event_calendar.csv')\n",
    "    dfs['iv'] = pd.read_csv('industry_volume.csv')\n",
    "    dfs['dem'] = pd.read_csv('demographics.csv')\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_and_merge():\n",
    "    clean_psp()\n",
    "    clean_hv()\n",
    "    dfs = read_csvs()\n",
    "    base = dfs['hv'].copy()\n",
    "    base = base.merge(dfs['psp'],how='left',on=['Agency','SKU','YearMonth'])\n",
    "    base = base.merge(dfs['wea'],how='left',on=['Agency','YearMonth'])\n",
    "    base = base.merge(dfs['iss'],how='left',on=['YearMonth'])\n",
    "    base = base.merge(dfs['ec'],how='left',on=['YearMonth'])\n",
    "    base = base.merge(dfs['iv'],how='left',on=['YearMonth'])\n",
    "    base = base.merge(dfs['dem'],how='left',on=['Agency'])    \n",
    "    base.columns = ['Agency', 'SKU', 'YearMonth', 'Volume', 'Price', 'Sales', 'Promo',\n",
    "       'Temp', 'SodaVol', 'Easter', 'GoodFriday', 'NewYear',\n",
    "       'Christmas', 'LaborDay', 'IndDay', 'RevDay','RegGames ', 'FIFA', 'FootballGC',\n",
    "       'BeerCapital', 'MusicFest', 'IndVol', 'Popu','Income']   \n",
    "    base = base.drop(['FIFA','FootballGC'],axis=1)\n",
    "    base.to_csv('integrated_train.csv',index=False)\n",
    "    \n",
    "    base = pd.read_csv('test/volume_forecast.csv')\n",
    "    base['YearMonth']=201801\n",
    "    base = base.merge(dfs['wea'],how='left',on=['YearMonth','Agency'])\n",
    "    base = base.merge(dfs['ec'],how='left',on=['YearMonth'])\n",
    "    base = base.merge(dfs['dem'],how='left',on=['Agency'])\n",
    "    base = base.drop(['Volume'],axis=1)\n",
    "    base.columns = ['Agency', 'SKU', 'YearMonth', 'Temp', 'Easter',\n",
    "           'GoodFriday', 'NewYear', 'Christmas', 'LaborDay', 'IndDay',\n",
    "           'RevDay', 'RegGames ', 'FIFA',\n",
    "           'FootballGC', 'BeerCapital', 'MusicFest',\n",
    "           'Popu', 'Income']\n",
    "    base.to_csv('integrated_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clean_and_merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
