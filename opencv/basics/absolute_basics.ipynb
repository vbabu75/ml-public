{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "def display_two_images(img1,img2):\n",
    "    _,axes = plt.subplots(1,2,figsize=(10,5))\n",
    "    axes[0].imshow(img1)\n",
    "    axes[1].imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and show an image\n",
    "def read_and_show_image(fn):\n",
    "    image = cv2.imread(fn)\n",
    "    window = cv2.namedWindow('Image',cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.imshow(window,image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyWindow('Image')\n",
    "\n",
    "#read_and_show_image('images/tower_bridge.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and show a video\n",
    "def read_and_show_video(fn):\n",
    "    window = cv2.namedWindow('Video',cv2.WINDOW_AUTOSIZE)\n",
    "    cap = cv2.VideoCapture()\n",
    "    if cap.open(fn):\n",
    "        (success,frame) = cap.read()\n",
    "        while(success):\n",
    "            cv2.imshow(window,frame)\n",
    "            if(cv2.waitKey(33) >=0):\n",
    "                break\n",
    "            (success,frame) = cap.read()\n",
    "    cv2.destroyWindow('Video')\n",
    "\n",
    "#read_and_show_video('videos/piano.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a trackbar slider to the video viewer for moving around \n",
    "# within the video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and show image inline\n",
    "def read_and_convert_image(fn):\n",
    "    image = cv2.imread(fn)\n",
    "    return cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(read_and_convert_image('images/tower_bridge.jpg'));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth image\n",
    "def smooth_image(image):\n",
    "    image = cv2.GaussianBlur(image,(5,5),3)\n",
    "    image = cv2.GaussianBlur(image,(5,5),3)\n",
    "    return image\n",
    "\n",
    "image = read_and_convert_image('images/tower_bridge.jpg')\n",
    "out = smooth_image(image)\n",
    "display_two_images(image,out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plain **downsampling** introduces high frequencies into the resulting image. So run a high pass filter and then downsample. Do this using the **pyrDown** method.**pyramid down**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = read_and_convert_image(\"images/tower_bridge.jpg\")\n",
    "display_two_images(image,cv2.pyrDown(image,image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Canny edge detector** writes to a single channel grayscale image. So convert the image first to grayscale and then run through the edge detector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cannyEdgeDetect(image):\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    edge_image = np.zeros_like(image)\n",
    "    edge_image = None\n",
    "    return cv2.Canny(image,threshold1=10,\n",
    "                     threshold2=100,apertureSize=3,L2gradient=True)\n",
    "\n",
    "image = read_and_convert_image(\"images/tower_bridge.jpg\")\n",
    "edge = cannyEdgeDetect(image)\n",
    "_,axes = plt.subplots(1,2,figsize=(10,5))\n",
    "axes[0].imshow(image)\n",
    "axes[1].imshow(edge,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pyrDown and canny, get a cleaner primary edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primaryEdgeDetect(image):\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    image = cv2.pyrDown(image)\n",
    "    image = cv2.pyrDown(image)\n",
    "    image = cv2.Canny(image,threshold1=10,threshold2=100,\n",
    "                     apertureSize=3,L2gradient=True)\n",
    "    return image\n",
    "image = read_and_convert_image(\"images/tower_bridge.jpg\")\n",
    "edge = primaryEdgeDetect(image)\n",
    "_,axes = plt.subplots(1,2,figsize=(10,5))\n",
    "axes[0].imshow(image)\n",
    "axes[1].imshow(edge,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Log polar transformed** format is like what our eye would see. Convert a video to this format and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertVideoToLogPolarTransform(ipfn,opfn):\n",
    "    cap = cv2.VideoCapture(ipfn)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    writer = cv2.VideoWriter(opfn,cv2.VideoWriter_fourcc('M','J','P','G'),\n",
    "                           fps,(width,height))\n",
    "    (success,frame) = cap.read()\n",
    "    while success:\n",
    "        lpframe = cv2.logPolar(frame,(frame.shape[0]/2,frame.shape[1]/2),\n",
    "                    40,cv2.WARP_FILL_OUTLIERS)\n",
    "        writer.write(lpframe)\n",
    "        (success,frame) = cap.read()\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    return True\n",
    "retval = convertVideoToLogPolarTransform('videos/piano.mp4',\n",
    "                                         'videos/piano_lpf.mp4')\n",
    "print(retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"videos/piano_lpf.mp4\",width=500,height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
