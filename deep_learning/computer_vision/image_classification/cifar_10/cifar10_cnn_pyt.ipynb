{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/font_manager.py:278: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# choose best device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# create data transforms. \n",
    "# Apart from the resize and normalization, \n",
    "# let us also do data augmentation\n",
    "batch_size=100\n",
    "mean = (0.5,0.5,0.5)\n",
    "std = (0.5,0.5,0.5)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.RandomAffine(0,shear=7,scale=(0.9,1.1)),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.1,0.1,0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n",
    "# Create the training and validation datasets\n",
    "train_ds = datasets.CIFAR10(root='./cifar_data',download=True,\n",
    "                           train=True,transform=train_transforms)\n",
    "val_ds = datasets.CIFAR10(root='./cifar_data',download=True,\n",
    "                         train=False,transform=val_transforms)\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_ds,shuffle=True,batch_size=batch_size)\n",
    "val_loader = DataLoader(val_ds,shuffle=False,batch_size=batch_size)\n",
    "classes = [\"airplane\",'automobile','bird','cat','deer',\n",
    "          'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View sample image\n",
    "def image_decode(tensor):\n",
    "    image = tensor.cpu().clone().detach().numpy()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = image*np.array(std)+np.array(mean)\n",
    "    image = image.clip(0,1)\n",
    "    return image\n",
    "\n",
    "def show_10_samples(samples,labels):\n",
    "    fig,axes = plt.subplots(2,5)\n",
    "    for row in range(2):\n",
    "        for col in range(5):\n",
    "            axis = axes[row,col]\n",
    "            index = row*5+col\n",
    "            axis.imshow(image_decode(samples[index]))\n",
    "            axis.set_title(classes[labels[index].item()])\n",
    "    plt.show()\n",
    "\n",
    "temp_samples,temp_labels = next(iter(val_loader))\n",
    "show_10_samples(temp_samples,temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "# (Conv+MaxPool)*3 with doubling of filters\n",
    "# Define the network, loss and optimizer\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(3,64,3,1,1)\n",
    "        self.c1a = nn.ReLU()\n",
    "        self.s1 = nn.MaxPool2d((2,2),2)\n",
    "        self.c2 = nn.Conv2d(64,128,3,1,1)\n",
    "        self.c2a = nn.ReLU()  \n",
    "        self.s2 = nn.MaxPool2d((2,2),2)\n",
    "        self.c3 = nn.Conv2d(128,256,3,1,1)\n",
    "        self.c3a = nn.ReLU()    \n",
    "        self.s3 = nn.MaxPool2d((2,2),2)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*256,1024)\n",
    "        self.fc1a = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1024,10)\n",
    "        self.fc2a = nn.Softmax(1)\n",
    "        \n",
    "        self.cnn_layers = [self.c1,self.c1a,self.s1,self.c2,self.c2a,self.s2,\n",
    "                           self.c3,self.c3a,self.s3]\n",
    "        self.fc_layers = [self.fc1,self.fc1a,self.fc2,self.fc2a]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "# Test net mathematics\n",
    "with torch.no_grad():\n",
    "    temp_samples = temp_samples.to(device)\n",
    "    temp_output = net.forward(temp_samples)\n",
    "    print(temp_output.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c1a): ReLU()\n",
      "  (s1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c2a): ReLU()\n",
      "  (s2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c3a): ReLU()\n",
      "  (s3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (fc1a): ReLU()\n",
      "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  (fc2a): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 Training loss: 2.087 Training accuracy: 0.365 Val loss: 1.985 Val accuracy: 0.469 Time taken: 33\n",
      "\n",
      "Epoch: 2 Training loss: 1.984 Training accuracy: 0.471 Val loss: 1.956 Val accuracy: 0.5 Time taken: 32\n",
      "\n",
      "Epoch: 3 Training loss: 1.945 Training accuracy: 0.51 Val loss: 1.922 Val accuracy: 0.535 Time taken: 32\n",
      "\n",
      "Epoch: 4 Training loss: 1.905 Training accuracy: 0.553 Val loss: 1.874 Val accuracy: 0.584 Time taken: 32\n",
      "\n",
      "Epoch: 5 Training loss: 1.894 Training accuracy: 0.563 Val loss: 1.861 Val accuracy: 0.596 Time taken: 31\n",
      "\n",
      "Epoch: 6 Training loss: 1.868 Training accuracy: 0.589 Val loss: 1.848 Val accuracy: 0.61 Time taken: 32\n",
      "\n",
      "Epoch: 7 Training loss: 1.863 Training accuracy: 0.596 Val loss: 1.83 Val accuracy: 0.628 Time taken: 32\n",
      "\n",
      "Epoch: 8 Training loss: 1.848 Training accuracy: 0.611 Val loss: 1.828 Val accuracy: 0.631 Time taken: 32\n",
      "\n",
      "Epoch: 9 Training loss: 1.842 Training accuracy: 0.616 Val loss: 1.839 Val accuracy: 0.619 Time taken: 32\n",
      "\n",
      "Epoch: 10 Training loss: 1.831 Training accuracy: 0.627 Val loss: 1.855 Val accuracy: 0.604 Time taken: 32\n",
      "\n",
      "Epoch: 11 Training loss: 1.829 Training accuracy: 0.63 Val loss: 1.808 Val accuracy: 0.652 Time taken: 32\n",
      "\n",
      "Epoch: 12 Training loss: 1.824 Training accuracy: 0.635 Val loss: 1.801 Val accuracy: 0.657 Time taken: 32\n",
      "\n",
      "Epoch: 13 Training loss: 1.813 Training accuracy: 0.646 Val loss: 1.805 Val accuracy: 0.653 Time taken: 32\n",
      "\n",
      "Epoch: 14 Training loss: 1.82 Training accuracy: 0.639 Val loss: 1.797 Val accuracy: 0.663 Time taken: 32\n",
      "\n",
      "Epoch: 15 Training loss: 1.815 Training accuracy: 0.644 Val loss: 1.819 Val accuracy: 0.642 Time taken: 33\n",
      "\n",
      "Epoch: 16 Training loss: 1.812 Training accuracy: 0.648 Val loss: 1.811 Val accuracy: 0.648 Time taken: 40\n",
      "\n",
      "Epoch: 17 Training loss: 1.812 Training accuracy: 0.648 Val loss: 1.801 Val accuracy: 0.659 Time taken: 40\n",
      "\n",
      "Epoch: 18 Training loss: 1.817 Training accuracy: 0.643 Val loss: 1.785 Val accuracy: 0.675 Time taken: 32\n",
      "\n",
      "Epoch: 19 Training loss: 1.81 Training accuracy: 0.65 Val loss: 1.808 Val accuracy: 0.651 Time taken: 32\n",
      "\n",
      "Epoch: 20 Training loss: 1.808 Training accuracy: 0.652 Val loss: 1.809 Val accuracy: 0.651 Time taken: 32\n",
      "\n",
      "Epoch: 21 Training loss: 1.812 Training accuracy: 0.649 Val loss: 1.784 Val accuracy: 0.676 Time taken: 32\n",
      "\n",
      "Epoch: 22 Training loss: 1.804 Training accuracy: 0.656 Val loss: 1.796 Val accuracy: 0.664 Time taken: 32\n",
      "\n",
      "Epoch: 23 Training loss: 1.824 Training accuracy: 0.636 Val loss: 1.843 Val accuracy: 0.618 Time taken: 32\n",
      "\n",
      "Epoch: 24 Training loss: 1.82 Training accuracy: 0.64 Val loss: 1.819 Val accuracy: 0.641 Time taken: 32\n",
      "\n",
      "Epoch: 25 Training loss: 1.822 Training accuracy: 0.638 Val loss: 1.799 Val accuracy: 0.661 Time taken: 32\n",
      "\n",
      "Epoch: 26 Training loss: 1.825 Training accuracy: 0.636 Val loss: 1.789 Val accuracy: 0.671 Time taken: 32\n",
      "\n",
      "Epoch: 27 Training loss: 1.827 Training accuracy: 0.633 Val loss: 1.808 Val accuracy: 0.653 Time taken: 32\n",
      "\n",
      "Epoch: 28 Training loss: 1.826 Training accuracy: 0.635 Val loss: 1.821 Val accuracy: 0.639 Time taken: 32\n",
      "\n",
      "Epoch: 29 Training loss: 1.836 Training accuracy: 0.625 Val loss: 1.789 Val accuracy: 0.672 Time taken: 32\n",
      "\n",
      "Epoch: 30 Training loss: 1.837 Training accuracy: 0.624 Val loss: 1.796 Val accuracy: 0.664 Time taken: 32\n",
      "Training accuracies: [0.365, 0.471, 0.51, 0.553, 0.563, 0.589, 0.596, 0.611, 0.616, 0.627, 0.63, 0.635, 0.646, 0.639, 0.644, 0.648, 0.648, 0.643, 0.65, 0.652, 0.649, 0.656, 0.636, 0.64, 0.638, 0.636, 0.633, 0.635, 0.625, 0.624]\n",
      "Validation accuracies: [0.469, 0.5, 0.535, 0.584, 0.596, 0.61, 0.628, 0.631, 0.619, 0.604, 0.652, 0.657, 0.653, 0.663, 0.642, 0.648, 0.659, 0.675, 0.651, 0.651, 0.676, 0.664, 0.618, 0.641, 0.661, 0.671, 0.653, 0.639, 0.672, 0.664]\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "epochs = 30\n",
    "train_accuracies=[]\n",
    "val_accuracies=[]\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    t1 = time.time() \n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    for index,(samples,labels) in enumerate(train_loader):\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net.forward(samples)\n",
    "        loss = criterion(outputs,labels)\n",
    "        preds = torch.argmax(outputs,1)\n",
    "        total_loss += loss\n",
    "        total_correct += torch.sum(preds == labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if index % 50==49:\n",
    "#             print('.',end='')\n",
    "    with torch.no_grad():\n",
    "        val_loss=0\n",
    "        val_correct=0\n",
    "        for samples,labels in val_loader:\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net.forward(samples)\n",
    "            loss = criterion(outputs,labels)\n",
    "            preds = torch.argmax(outputs,1)\n",
    "            val_loss += loss\n",
    "            val_correct += torch.sum(preds==labels)\n",
    "        print('\\nEpoch:',epoch+1,\n",
    "             'Training loss:',round(total_loss.item()*batch_size/len(train_ds),3),\n",
    "             'Training accuracy:',round(total_correct.item()/len(train_ds),3),\n",
    "             'Val loss:',round(val_loss.item()*batch_size/len(val_ds),3),\n",
    "             'Val accuracy:',round(val_correct.item()/len(val_ds),3),\n",
    "             'Time taken:',round(time.time()-t1))\n",
    "        train_accuracies.append(round(total_correct.item()/len(train_ds),3))\n",
    "        val_accuracies.append(round(val_correct.item()/len(val_ds),3))\n",
    "        train_losses.append(round(total_loss.item()*batch_size/len(train_ds),3))\n",
    "        val_losses.append(round(val_loss.item()*batch_size/len(val_ds),3))\n",
    "\n",
    "print(\"Training accuracies:\",train_accuracies)\n",
    "print(\"Validation accuracies:\",val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "Net(\n",
      "  (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c1a): ReLU()\n",
      "  (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c2a): ReLU()\n",
      "  (s1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c3a): ReLU()\n",
      "  (s2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c4a): ReLU()\n",
      "  (s3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (fc1a): ReLU()\n",
      "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  (fc2a): Softmax()\n",
      ")\n",
      "\n",
      "Epoch: 1 Training loss: 2.138 Training accuracy: 0.314 Val loss: 2.064 Val accuracy: 0.388 Time taken: 31\n",
      "\n",
      "Epoch: 2 Training loss: 2.032 Training accuracy: 0.423 Val loss: 2.004 Val accuracy: 0.453 Time taken: 31\n",
      "\n",
      "Epoch: 3 Training loss: 1.976 Training accuracy: 0.48 Val loss: 1.944 Val accuracy: 0.514 Time taken: 31\n",
      "\n",
      "Epoch: 4 Training loss: 1.94 Training accuracy: 0.517 Val loss: 1.928 Val accuracy: 0.53 Time taken: 31\n",
      "\n",
      "Epoch: 5 Training loss: 1.921 Training accuracy: 0.537 Val loss: 1.899 Val accuracy: 0.558 Time taken: 31\n",
      "\n",
      "Epoch: 6 Training loss: 1.896 Training accuracy: 0.562 Val loss: 1.866 Val accuracy: 0.591 Time taken: 31\n",
      "\n",
      "Epoch: 7 Training loss: 1.881 Training accuracy: 0.577 Val loss: 1.854 Val accuracy: 0.604 Time taken: 31\n",
      "\n",
      "Epoch: 8 Training loss: 1.864 Training accuracy: 0.594 Val loss: 1.838 Val accuracy: 0.622 Time taken: 31\n",
      "\n",
      "Epoch: 9 Training loss: 1.851 Training accuracy: 0.608 Val loss: 1.823 Val accuracy: 0.635 Time taken: 31\n",
      "\n",
      "Epoch: 10 Training loss: 1.846 Training accuracy: 0.613 Val loss: 1.838 Val accuracy: 0.622 Time taken: 31\n",
      "\n",
      "Epoch: 11 Training loss: 1.845 Training accuracy: 0.614 Val loss: 1.827 Val accuracy: 0.632 Time taken: 31\n",
      "\n",
      "Epoch: 12 Training loss: 1.843 Training accuracy: 0.616 Val loss: 1.806 Val accuracy: 0.652 Time taken: 32\n",
      "\n",
      "Epoch: 13 Training loss: 1.834 Training accuracy: 0.624 Val loss: 1.816 Val accuracy: 0.642 Time taken: 31\n",
      "\n",
      "Epoch: 14 Training loss: 1.832 Training accuracy: 0.627 Val loss: 1.844 Val accuracy: 0.615 Time taken: 31\n",
      "\n",
      "Epoch: 15 Training loss: 1.832 Training accuracy: 0.627 Val loss: 1.802 Val accuracy: 0.658 Time taken: 31\n",
      "\n",
      "Epoch: 16 Training loss: 1.838 Training accuracy: 0.622 Val loss: 1.84 Val accuracy: 0.621 Time taken: 31\n",
      "\n",
      "Epoch: 17 Training loss: 1.834 Training accuracy: 0.626 Val loss: 1.812 Val accuracy: 0.647 Time taken: 31\n",
      "\n",
      "Epoch: 18 Training loss: 1.836 Training accuracy: 0.624 Val loss: 1.849 Val accuracy: 0.61 Time taken: 31\n",
      "\n",
      "Epoch: 19 Training loss: 1.848 Training accuracy: 0.612 Val loss: 1.805 Val accuracy: 0.654 Time taken: 31\n",
      "\n",
      "Epoch: 20 Training loss: 1.851 Training accuracy: 0.609 Val loss: 1.834 Val accuracy: 0.627 Time taken: 31\n",
      "\n",
      "Epoch: 21 Training loss: 1.841 Training accuracy: 0.62 Val loss: 1.798 Val accuracy: 0.662 Time taken: 31\n",
      "\n",
      "Epoch: 22 Training loss: 1.846 Training accuracy: 0.615 Val loss: 1.823 Val accuracy: 0.638 Time taken: 31\n",
      "\n",
      "Epoch: 23 Training loss: 1.853 Training accuracy: 0.607 Val loss: 1.848 Val accuracy: 0.612 Time taken: 31\n",
      "\n",
      "Epoch: 24 Training loss: 1.854 Training accuracy: 0.607 Val loss: 1.827 Val accuracy: 0.634 Time taken: 31\n",
      "\n",
      "Epoch: 25 Training loss: 1.859 Training accuracy: 0.602 Val loss: 1.819 Val accuracy: 0.642 Time taken: 31\n",
      "\n",
      "Epoch: 26 Training loss: 1.872 Training accuracy: 0.589 Val loss: 1.815 Val accuracy: 0.646 Time taken: 31\n",
      "\n",
      "Epoch: 27 Training loss: 1.888 Training accuracy: 0.573 Val loss: 1.876 Val accuracy: 0.585 Time taken: 31\n",
      "\n",
      "Epoch: 28 Training loss: 1.892 Training accuracy: 0.569 Val loss: 1.938 Val accuracy: 0.523 Time taken: 31\n",
      "\n",
      "Epoch: 29 Training loss: 1.902 Training accuracy: 0.559 Val loss: 1.853 Val accuracy: 0.608 Time taken: 31\n",
      "\n",
      "Epoch: 30 Training loss: 1.89 Training accuracy: 0.571 Val loss: 1.891 Val accuracy: 0.57 Time taken: 31\n",
      "Training losses: [2.138, 2.032, 1.976, 1.94, 1.921, 1.896, 1.881, 1.864, 1.851, 1.846, 1.845, 1.843, 1.834, 1.832, 1.832, 1.838, 1.834, 1.836, 1.848, 1.851, 1.841, 1.846, 1.853, 1.854, 1.859, 1.872, 1.888, 1.892, 1.902, 1.89]\n",
      "Training accuracies: [0.314, 0.423, 0.48, 0.517, 0.537, 0.562, 0.577, 0.594, 0.608, 0.613, 0.614, 0.616, 0.624, 0.627, 0.627, 0.622, 0.626, 0.624, 0.612, 0.609, 0.62, 0.615, 0.607, 0.607, 0.602, 0.589, 0.573, 0.569, 0.559, 0.571]\n",
      "Validation losses: [2.064, 2.004, 1.944, 1.928, 1.899, 1.866, 1.854, 1.838, 1.823, 1.838, 1.827, 1.806, 1.816, 1.844, 1.802, 1.84, 1.812, 1.849, 1.805, 1.834, 1.798, 1.823, 1.848, 1.827, 1.819, 1.815, 1.876, 1.938, 1.853, 1.891]\n",
      "Validation accuracies: [0.388, 0.453, 0.514, 0.53, 0.558, 0.591, 0.604, 0.622, 0.635, 0.622, 0.632, 0.652, 0.642, 0.615, 0.658, 0.621, 0.647, 0.61, 0.654, 0.627, 0.662, 0.638, 0.612, 0.634, 0.642, 0.646, 0.585, 0.523, 0.608, 0.57]\n"
     ]
    }
   ],
   "source": [
    "# Network: (Conv+Conv+MaxPool)+(Conv+MaxPool)+(Conv+MaxPool)\n",
    "# Define the network, loss and optimizer\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(3,64,3,1,1)\n",
    "        self.c1a = nn.ReLU()\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.c2a = nn.ReLU()        \n",
    "        self.s1 = nn.MaxPool2d((2,2),2)\n",
    "        self.c3 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.c3a = nn.ReLU()  \n",
    "        self.s2 = nn.MaxPool2d((2,2),2)\n",
    "        self.c4 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.c4a = nn.ReLU()    \n",
    "        self.s3 = nn.MaxPool2d((2,2),2)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*64,1024)\n",
    "        self.fc1a = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1024,10)\n",
    "        self.fc2a = nn.Softmax(1)\n",
    "        \n",
    "        self.cnn_layers = [self.c1,self.c1a,self.c2,self.c2a,self.s1,self.c3,self.c3a,self.s2,\n",
    "                           self.c4,self.c4a,self.s3]\n",
    "        self.fc_layers = [self.fc1,self.fc1a,self.fc2,self.fc2a]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "# Test net mathematics\n",
    "with torch.no_grad():\n",
    "    temp_samples = temp_samples.to(device)\n",
    "    temp_output = net.forward(temp_samples)\n",
    "    print(temp_output.shape)\n",
    "print(net)\n",
    "# train the network\n",
    "epochs = 30\n",
    "train_accuracies=[]\n",
    "val_accuracies=[]\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    t1 = time.time() \n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    for index,(samples,labels) in enumerate(train_loader):\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net.forward(samples)\n",
    "        loss = criterion(outputs,labels)\n",
    "        preds = torch.argmax(outputs,1)\n",
    "        total_loss += loss\n",
    "        total_correct += torch.sum(preds == labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if index % 50==49:\n",
    "#             print('.',end='')\n",
    "    with torch.no_grad():\n",
    "        val_loss=0\n",
    "        val_correct=0\n",
    "        for samples,labels in val_loader:\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net.forward(samples)\n",
    "            loss = criterion(outputs,labels)\n",
    "            preds = torch.argmax(outputs,1)\n",
    "            val_loss += loss\n",
    "            val_correct += torch.sum(preds==labels)\n",
    "        print('\\nEpoch:',epoch+1,\n",
    "             'Training loss:',round(total_loss.item()*batch_size/len(train_ds),3),\n",
    "             'Training accuracy:',round(total_correct.item()/len(train_ds),3),\n",
    "             'Val loss:',round(val_loss.item()*batch_size/len(val_ds),3),\n",
    "             'Val accuracy:',round(val_correct.item()/len(val_ds),3),\n",
    "             'Time taken:',round(time.time()-t1))\n",
    "        train_accuracies.append(round(total_correct.item()/len(train_ds),3))\n",
    "        val_accuracies.append(round(val_correct.item()/len(val_ds),3))\n",
    "        train_losses.append(round(total_loss.item()*batch_size/len(train_ds),3))\n",
    "        val_losses.append(round(val_loss.item()*batch_size/len(val_ds),3))\n",
    "print(\"Training losses:\",train_losses)\n",
    "print(\"Training accuracies:\",train_accuracies)\n",
    "print(\"Validation losses:\",val_losses)\n",
    "print(\"Validation accuracies:\",val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "Net(\n",
      "  (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c1a): ReLU()\n",
      "  (s1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c2a): ReLU()\n",
      "  (c3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c3a): ReLU()\n",
      "  (s2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c4a): ReLU()\n",
      "  (s3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (fc1a): ReLU()\n",
      "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  (fc2a): Softmax()\n",
      ")\n",
      "\n",
      "Epoch: 1 Training loss: 2.178 Training accuracy: 0.272 Val loss: 2.09 Val accuracy: 0.365 Time taken: 31\n",
      "\n",
      "Epoch: 2 Training loss: 2.045 Training accuracy: 0.409 Val loss: 1.998 Val accuracy: 0.456 Time taken: 31\n",
      "\n",
      "Epoch: 3 Training loss: 2.0 Training accuracy: 0.456 Val loss: 1.977 Val accuracy: 0.478 Time taken: 31\n",
      "\n",
      "Epoch: 4 Training loss: 1.963 Training accuracy: 0.494 Val loss: 1.956 Val accuracy: 0.501 Time taken: 31\n",
      "\n",
      "Epoch: 5 Training loss: 1.947 Training accuracy: 0.51 Val loss: 1.926 Val accuracy: 0.531 Time taken: 31\n",
      "\n",
      "Epoch: 6 Training loss: 1.933 Training accuracy: 0.525 Val loss: 1.913 Val accuracy: 0.545 Time taken: 31\n",
      "\n",
      "Epoch: 7 Training loss: 1.917 Training accuracy: 0.541 Val loss: 1.895 Val accuracy: 0.563 Time taken: 31\n",
      "\n",
      "Epoch: 8 Training loss: 1.913 Training accuracy: 0.544 Val loss: 1.885 Val accuracy: 0.574 Time taken: 31\n",
      "\n",
      "Epoch: 9 Training loss: 1.901 Training accuracy: 0.557 Val loss: 1.879 Val accuracy: 0.579 Time taken: 31\n",
      "\n",
      "Epoch: 10 Training loss: 1.89 Training accuracy: 0.568 Val loss: 1.861 Val accuracy: 0.598 Time taken: 31\n",
      "\n",
      "Epoch: 11 Training loss: 1.88 Training accuracy: 0.578 Val loss: 1.869 Val accuracy: 0.591 Time taken: 31\n",
      "\n",
      "Epoch: 12 Training loss: 1.874 Training accuracy: 0.585 Val loss: 1.856 Val accuracy: 0.602 Time taken: 31\n",
      "\n",
      "Epoch: 13 Training loss: 1.877 Training accuracy: 0.582 Val loss: 1.858 Val accuracy: 0.601 Time taken: 31\n",
      "\n",
      "Epoch: 14 Training loss: 1.88 Training accuracy: 0.579 Val loss: 1.882 Val accuracy: 0.576 Time taken: 31\n",
      "\n",
      "Epoch: 15 Training loss: 1.879 Training accuracy: 0.581 Val loss: 1.841 Val accuracy: 0.619 Time taken: 31\n",
      "\n",
      "Epoch: 16 Training loss: 1.874 Training accuracy: 0.585 Val loss: 1.888 Val accuracy: 0.572 Time taken: 31\n",
      "\n",
      "Epoch: 17 Training loss: 1.887 Training accuracy: 0.573 Val loss: 1.861 Val accuracy: 0.599 Time taken: 31\n",
      "\n",
      "Epoch: 18 Training loss: 1.886 Training accuracy: 0.574 Val loss: 1.855 Val accuracy: 0.606 Time taken: 31\n",
      "\n",
      "Epoch: 19 Training loss: 1.888 Training accuracy: 0.572 Val loss: 1.91 Val accuracy: 0.551 Time taken: 31\n",
      "\n",
      "Epoch: 20 Training loss: 1.905 Training accuracy: 0.555 Val loss: 1.878 Val accuracy: 0.582 Time taken: 31\n",
      "\n",
      "Epoch: 21 Training loss: 1.903 Training accuracy: 0.557 Val loss: 1.872 Val accuracy: 0.588 Time taken: 31\n",
      "\n",
      "Epoch: 22 Training loss: 1.896 Training accuracy: 0.564 Val loss: 1.909 Val accuracy: 0.552 Time taken: 31\n",
      "\n",
      "Epoch: 23 Training loss: 1.902 Training accuracy: 0.558 Val loss: 1.902 Val accuracy: 0.558 Time taken: 31\n",
      "\n",
      "Epoch: 24 Training loss: 1.91 Training accuracy: 0.55 Val loss: 1.885 Val accuracy: 0.576 Time taken: 31\n",
      "\n",
      "Epoch: 25 Training loss: 1.935 Training accuracy: 0.526 Val loss: 1.927 Val accuracy: 0.534 Time taken: 31\n",
      "\n",
      "Epoch: 26 Training loss: 1.934 Training accuracy: 0.527 Val loss: 1.916 Val accuracy: 0.545 Time taken: 31\n",
      "\n",
      "Epoch: 27 Training loss: 1.95 Training accuracy: 0.511 Val loss: 1.967 Val accuracy: 0.494 Time taken: 31\n",
      "\n",
      "Epoch: 28 Training loss: 1.96 Training accuracy: 0.5 Val loss: 1.966 Val accuracy: 0.495 Time taken: 31\n",
      "\n",
      "Epoch: 29 Training loss: 1.947 Training accuracy: 0.514 Val loss: 1.951 Val accuracy: 0.51 Time taken: 31\n",
      "\n",
      "Epoch: 30 Training loss: 1.967 Training accuracy: 0.494 Val loss: 1.965 Val accuracy: 0.496 Time taken: 31\n",
      "Training losses: [2.178, 2.045, 2.0, 1.963, 1.947, 1.933, 1.917, 1.913, 1.901, 1.89, 1.88, 1.874, 1.877, 1.88, 1.879, 1.874, 1.887, 1.886, 1.888, 1.905, 1.903, 1.896, 1.902, 1.91, 1.935, 1.934, 1.95, 1.96, 1.947, 1.967]\n",
      "Training accuracies: [0.272, 0.409, 0.456, 0.494, 0.51, 0.525, 0.541, 0.544, 0.557, 0.568, 0.578, 0.585, 0.582, 0.579, 0.581, 0.585, 0.573, 0.574, 0.572, 0.555, 0.557, 0.564, 0.558, 0.55, 0.526, 0.527, 0.511, 0.5, 0.514, 0.494]\n",
      "Validation losses: [2.09, 1.998, 1.977, 1.956, 1.926, 1.913, 1.895, 1.885, 1.879, 1.861, 1.869, 1.856, 1.858, 1.882, 1.841, 1.888, 1.861, 1.855, 1.91, 1.878, 1.872, 1.909, 1.902, 1.885, 1.927, 1.916, 1.967, 1.966, 1.951, 1.965]\n",
      "Validation accuracies: [0.365, 0.456, 0.478, 0.501, 0.531, 0.545, 0.563, 0.574, 0.579, 0.598, 0.591, 0.602, 0.601, 0.576, 0.619, 0.572, 0.599, 0.606, 0.551, 0.582, 0.588, 0.552, 0.558, 0.576, 0.534, 0.545, 0.494, 0.495, 0.51, 0.496]\n"
     ]
    }
   ],
   "source": [
    "# Network: (Conv+MaxPool)+(Conv+Conv+MaxPool)+(Conv+MaxPool)\n",
    "# Define the network, loss and optimizer\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(3,64,3,1,1)\n",
    "        self.c1a = nn.ReLU()\n",
    "        self.s1 = nn.MaxPool2d((2,2),2)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.c2a = nn.ReLU()        \n",
    "        self.c3 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.c3a = nn.ReLU()  \n",
    "        self.s2 = nn.MaxPool2d((2,2),2)\n",
    "        self.c4 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.c4a = nn.ReLU()    \n",
    "        self.s3 = nn.MaxPool2d((2,2),2)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*64,1024)\n",
    "        self.fc1a = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1024,10)\n",
    "        self.fc2a = nn.Softmax(1)\n",
    "        \n",
    "        self.cnn_layers = [self.c1,self.c1a,self.s1,self.c2,self.c2a,self.c3,self.c3a,self.s2,\n",
    "                           self.c4,self.c4a,self.s3]\n",
    "        self.fc_layers = [self.fc1,self.fc1a,self.fc2,self.fc2a]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "# Test net mathematics\n",
    "with torch.no_grad():\n",
    "    temp_samples = temp_samples.to(device)\n",
    "    temp_output = net.forward(temp_samples)\n",
    "    print(temp_output.shape)\n",
    "print(net)\n",
    "# train the network\n",
    "epochs = 30\n",
    "train_accuracies=[]\n",
    "val_accuracies=[]\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    t1 = time.time() \n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    for index,(samples,labels) in enumerate(train_loader):\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net.forward(samples)\n",
    "        loss = criterion(outputs,labels)\n",
    "        preds = torch.argmax(outputs,1)\n",
    "        total_loss += loss\n",
    "        total_correct += torch.sum(preds == labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if index % 50==49:\n",
    "#             print('.',end='')\n",
    "    with torch.no_grad():\n",
    "        val_loss=0\n",
    "        val_correct=0\n",
    "        for samples,labels in val_loader:\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net.forward(samples)\n",
    "            loss = criterion(outputs,labels)\n",
    "            preds = torch.argmax(outputs,1)\n",
    "            val_loss += loss\n",
    "            val_correct += torch.sum(preds==labels)\n",
    "        print('\\nEpoch:',epoch+1,\n",
    "             'Training loss:',round(total_loss.item()*batch_size/len(train_ds),3),\n",
    "             'Training accuracy:',round(total_correct.item()/len(train_ds),3),\n",
    "             'Val loss:',round(val_loss.item()*batch_size/len(val_ds),3),\n",
    "             'Val accuracy:',round(val_correct.item()/len(val_ds),3),\n",
    "             'Time taken:',round(time.time()-t1))\n",
    "        train_accuracies.append(round(total_correct.item()/len(train_ds),3))\n",
    "        val_accuracies.append(round(val_correct.item()/len(val_ds),3))\n",
    "        train_losses.append(round(total_loss.item()*batch_size/len(train_ds),3))\n",
    "        val_losses.append(round(val_loss.item()*batch_size/len(val_ds),3))\n",
    "print(\"Training losses:\",train_losses)\n",
    "print(\"Training accuracies:\",train_accuracies)\n",
    "print(\"Validation losses:\",val_losses)\n",
    "print(\"Validation accuracies:\",val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "Net(\n",
      "  (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c1a): ReLU()\n",
      "  (s1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c2a): ReLU()\n",
      "  (s2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c3a): ReLU()\n",
      "  (c4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c4a): ReLU()\n",
      "  (s3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (fc1a): ReLU()\n",
      "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  (fc2a): Softmax()\n",
      ")\n",
      "\n",
      "Epoch: 1 Training loss: 2.144 Training accuracy: 0.305 Val loss: 2.045 Val accuracy: 0.41 Time taken: 31\n",
      "\n",
      "Epoch: 2 Training loss: 2.034 Training accuracy: 0.422 Val loss: 1.995 Val accuracy: 0.459 Time taken: 31\n",
      "\n",
      "Epoch: 3 Training loss: 1.99 Training accuracy: 0.466 Val loss: 1.946 Val accuracy: 0.51 Time taken: 31\n",
      "\n",
      "Epoch: 4 Training loss: 1.964 Training accuracy: 0.494 Val loss: 1.928 Val accuracy: 0.529 Time taken: 31\n",
      "\n",
      "Epoch: 5 Training loss: 1.939 Training accuracy: 0.518 Val loss: 1.907 Val accuracy: 0.55 Time taken: 31\n",
      "\n",
      "Epoch: 6 Training loss: 1.925 Training accuracy: 0.533 Val loss: 1.885 Val accuracy: 0.572 Time taken: 31\n",
      "\n",
      "Epoch: 7 Training loss: 1.906 Training accuracy: 0.552 Val loss: 1.896 Val accuracy: 0.562 Time taken: 31\n",
      "\n",
      "Epoch: 8 Training loss: 1.9 Training accuracy: 0.558 Val loss: 1.914 Val accuracy: 0.544 Time taken: 31\n",
      "\n",
      "Epoch: 9 Training loss: 1.889 Training accuracy: 0.569 Val loss: 1.871 Val accuracy: 0.588 Time taken: 31\n",
      "\n",
      "Epoch: 10 Training loss: 1.881 Training accuracy: 0.577 Val loss: 1.877 Val accuracy: 0.581 Time taken: 31\n",
      "\n",
      "Epoch: 11 Training loss: 1.879 Training accuracy: 0.58 Val loss: 1.85 Val accuracy: 0.61 Time taken: 31\n",
      "\n",
      "Epoch: 12 Training loss: 1.868 Training accuracy: 0.591 Val loss: 1.888 Val accuracy: 0.571 Time taken: 31\n",
      "\n",
      "Epoch: 13 Training loss: 1.882 Training accuracy: 0.577 Val loss: 1.842 Val accuracy: 0.618 Time taken: 31\n",
      "\n",
      "Epoch: 14 Training loss: 1.888 Training accuracy: 0.572 Val loss: 1.883 Val accuracy: 0.577 Time taken: 31\n",
      "\n",
      "Epoch: 15 Training loss: 1.884 Training accuracy: 0.576 Val loss: 1.876 Val accuracy: 0.585 Time taken: 31\n",
      "\n",
      "Epoch: 16 Training loss: 1.886 Training accuracy: 0.574 Val loss: 1.884 Val accuracy: 0.576 Time taken: 31\n",
      "\n",
      "Epoch: 17 Training loss: 1.891 Training accuracy: 0.57 Val loss: 1.883 Val accuracy: 0.577 Time taken: 31\n",
      "\n",
      "Epoch: 18 Training loss: 1.893 Training accuracy: 0.567 Val loss: 1.911 Val accuracy: 0.55 Time taken: 31\n",
      "\n",
      "Epoch: 19 Training loss: 1.898 Training accuracy: 0.562 Val loss: 1.871 Val accuracy: 0.589 Time taken: 31\n",
      "\n",
      "Epoch: 20 Training loss: 1.909 Training accuracy: 0.552 Val loss: 1.864 Val accuracy: 0.596 Time taken: 31\n",
      "\n",
      "Epoch: 21 Training loss: 1.912 Training accuracy: 0.549 Val loss: 1.882 Val accuracy: 0.579 Time taken: 31\n",
      "\n",
      "Epoch: 22 Training loss: 1.912 Training accuracy: 0.549 Val loss: 1.904 Val accuracy: 0.556 Time taken: 31\n",
      "\n",
      "Epoch: 23 Training loss: 1.927 Training accuracy: 0.534 Val loss: 1.901 Val accuracy: 0.559 Time taken: 31\n",
      "\n",
      "Epoch: 24 Training loss: 1.959 Training accuracy: 0.502 Val loss: 1.927 Val accuracy: 0.534 Time taken: 31\n",
      "\n",
      "Epoch: 25 Training loss: 1.95 Training accuracy: 0.511 Val loss: 1.91 Val accuracy: 0.551 Time taken: 31\n",
      "\n",
      "Epoch: 26 Training loss: 1.958 Training accuracy: 0.503 Val loss: 1.901 Val accuracy: 0.56 Time taken: 31\n",
      "\n",
      "Epoch: 27 Training loss: 1.962 Training accuracy: 0.499 Val loss: 1.931 Val accuracy: 0.531 Time taken: 31\n",
      "\n",
      "Epoch: 28 Training loss: 1.982 Training accuracy: 0.479 Val loss: 1.94 Val accuracy: 0.52 Time taken: 31\n",
      "\n",
      "Epoch: 29 Training loss: 2.011 Training accuracy: 0.45 Val loss: 1.939 Val accuracy: 0.522 Time taken: 31\n",
      "\n",
      "Epoch: 30 Training loss: 1.994 Training accuracy: 0.467 Val loss: 1.957 Val accuracy: 0.504 Time taken: 31\n",
      "Training losses: [2.144, 2.034, 1.99, 1.964, 1.939, 1.925, 1.906, 1.9, 1.889, 1.881, 1.879, 1.868, 1.882, 1.888, 1.884, 1.886, 1.891, 1.893, 1.898, 1.909, 1.912, 1.912, 1.927, 1.959, 1.95, 1.958, 1.962, 1.982, 2.011, 1.994]\n",
      "Training accuracies: [0.305, 0.422, 0.466, 0.494, 0.518, 0.533, 0.552, 0.558, 0.569, 0.577, 0.58, 0.591, 0.577, 0.572, 0.576, 0.574, 0.57, 0.567, 0.562, 0.552, 0.549, 0.549, 0.534, 0.502, 0.511, 0.503, 0.499, 0.479, 0.45, 0.467]\n",
      "Validation losses: [2.045, 1.995, 1.946, 1.928, 1.907, 1.885, 1.896, 1.914, 1.871, 1.877, 1.85, 1.888, 1.842, 1.883, 1.876, 1.884, 1.883, 1.911, 1.871, 1.864, 1.882, 1.904, 1.901, 1.927, 1.91, 1.901, 1.931, 1.94, 1.939, 1.957]\n",
      "Validation accuracies: [0.41, 0.459, 0.51, 0.529, 0.55, 0.572, 0.562, 0.544, 0.588, 0.581, 0.61, 0.571, 0.618, 0.577, 0.585, 0.576, 0.577, 0.55, 0.589, 0.596, 0.579, 0.556, 0.559, 0.534, 0.551, 0.56, 0.531, 0.52, 0.522, 0.504]\n"
     ]
    }
   ],
   "source": [
    "# Network: (Conv+MaxPool)+(Conv+MaxPool)+(Conv+Conv+MaxPool)\n",
    "# Define the network, loss and optimizer\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(3,64,3,1,1)\n",
    "        self.c1a = nn.ReLU()\n",
    "        self.s1 = nn.MaxPool2d((2,2),2)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.c2a = nn.ReLU()        \n",
    "        self.s2 = nn.MaxPool2d((2,2),2)\n",
    "        self.c3 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.c3a = nn.ReLU()  \n",
    "        self.c4 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.c4a = nn.ReLU()    \n",
    "        self.s3 = nn.MaxPool2d((2,2),2)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*64,1024)\n",
    "        self.fc1a = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1024,10)\n",
    "        self.fc2a = nn.Softmax(1)\n",
    "        \n",
    "        self.cnn_layers = [self.c1,self.c1a,self.s1,self.c2,self.c2a,self.s2,self.c3,self.c3a,\n",
    "                           self.c4,self.c4a,self.s3]\n",
    "        self.fc_layers = [self.fc1,self.fc1a,self.fc2,self.fc2a]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "# Test net mathematics\n",
    "with torch.no_grad():\n",
    "    temp_samples = temp_samples.to(device)\n",
    "    temp_output = net.forward(temp_samples)\n",
    "    print(temp_output.shape)\n",
    "print(net)\n",
    "# train the network\n",
    "epochs = 30\n",
    "train_accuracies=[]\n",
    "val_accuracies=[]\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    t1 = time.time() \n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    for index,(samples,labels) in enumerate(train_loader):\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net.forward(samples)\n",
    "        loss = criterion(outputs,labels)\n",
    "        preds = torch.argmax(outputs,1)\n",
    "        total_loss += loss\n",
    "        total_correct += torch.sum(preds == labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if index % 50==49:\n",
    "#             print('.',end='')\n",
    "    with torch.no_grad():\n",
    "        val_loss=0\n",
    "        val_correct=0\n",
    "        for samples,labels in val_loader:\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net.forward(samples)\n",
    "            loss = criterion(outputs,labels)\n",
    "            preds = torch.argmax(outputs,1)\n",
    "            val_loss += loss\n",
    "            val_correct += torch.sum(preds==labels)\n",
    "        print('\\nEpoch:',epoch+1,\n",
    "             'Training loss:',round(total_loss.item()*batch_size/len(train_ds),3),\n",
    "             'Training accuracy:',round(total_correct.item()/len(train_ds),3),\n",
    "             'Val loss:',round(val_loss.item()*batch_size/len(val_ds),3),\n",
    "             'Val accuracy:',round(val_correct.item()/len(val_ds),3),\n",
    "             'Time taken:',round(time.time()-t1))\n",
    "        train_accuracies.append(round(total_correct.item()/len(train_ds),3))\n",
    "        val_accuracies.append(round(val_correct.item()/len(val_ds),3))\n",
    "        train_losses.append(round(total_loss.item()*batch_size/len(train_ds),3))\n",
    "        val_losses.append(round(val_loss.item()*batch_size/len(val_ds),3))\n",
    "print(\"Training losses:\",train_losses)\n",
    "print(\"Training accuracies:\",train_accuracies)\n",
    "print(\"Validation losses:\",val_losses)\n",
    "print(\"Validation accuracies:\",val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "Net(\n",
      "  (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c1a): ReLU()\n",
      "  (c2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c2a): ReLU()\n",
      "  (s1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c3a): ReLU()\n",
      "  (s2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c4a): ReLU()\n",
      "  (s3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc1a): ReLU()\n",
      "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  (fc2a): Softmax()\n",
      ")\n",
      "\n",
      "Epoch: 1 Training loss: 2.166 Training accuracy: 0.286 Val loss: 2.069 Val accuracy: 0.386 Time taken: 58\n",
      "\n",
      "Epoch: 2 Training loss: 2.053 Training accuracy: 0.402 Val loss: 2.014 Val accuracy: 0.441 Time taken: 58\n",
      "\n",
      "Epoch: 3 Training loss: 2.009 Training accuracy: 0.447 Val loss: 1.957 Val accuracy: 0.498 Time taken: 58\n",
      "\n",
      "Epoch: 4 Training loss: 1.964 Training accuracy: 0.492 Val loss: 1.933 Val accuracy: 0.525 Time taken: 58\n",
      "\n",
      "Epoch: 5 Training loss: 1.947 Training accuracy: 0.51 Val loss: 1.936 Val accuracy: 0.522 Time taken: 58\n",
      "\n",
      "Epoch: 6 Training loss: 1.93 Training accuracy: 0.528 Val loss: 1.923 Val accuracy: 0.536 Time taken: 58\n",
      "\n",
      "Epoch: 7 Training loss: 1.907 Training accuracy: 0.551 Val loss: 1.871 Val accuracy: 0.588 Time taken: 58\n",
      "\n",
      "Epoch: 8 Training loss: 1.888 Training accuracy: 0.57 Val loss: 1.862 Val accuracy: 0.596 Time taken: 58\n",
      "\n",
      "Epoch: 9 Training loss: 1.887 Training accuracy: 0.572 Val loss: 1.87 Val accuracy: 0.589 Time taken: 58\n",
      "\n",
      "Epoch: 10 Training loss: 1.874 Training accuracy: 0.585 Val loss: 1.849 Val accuracy: 0.609 Time taken: 58\n",
      "\n",
      "Epoch: 11 Training loss: 1.866 Training accuracy: 0.594 Val loss: 1.853 Val accuracy: 0.607 Time taken: 58\n",
      "\n",
      "Epoch: 12 Training loss: 1.87 Training accuracy: 0.589 Val loss: 1.858 Val accuracy: 0.602 Time taken: 58\n",
      "\n",
      "Epoch: 13 Training loss: 1.858 Training accuracy: 0.602 Val loss: 1.903 Val accuracy: 0.557 Time taken: 58\n",
      "\n",
      "Epoch: 14 Training loss: 1.876 Training accuracy: 0.584 Val loss: 1.869 Val accuracy: 0.592 Time taken: 58\n",
      "\n",
      "Epoch: 15 Training loss: 1.863 Training accuracy: 0.597 Val loss: 1.872 Val accuracy: 0.588 Time taken: 58\n",
      "\n",
      "Epoch: 16 Training loss: 1.868 Training accuracy: 0.592 Val loss: 1.884 Val accuracy: 0.576 Time taken: 58\n",
      "\n",
      "Epoch: 17 Training loss: 1.875 Training accuracy: 0.585 Val loss: 1.889 Val accuracy: 0.572 Time taken: 58\n",
      "\n",
      "Epoch: 18 Training loss: 1.873 Training accuracy: 0.587 Val loss: 1.841 Val accuracy: 0.619 Time taken: 58\n",
      "\n",
      "Epoch: 19 Training loss: 1.894 Training accuracy: 0.567 Val loss: 1.901 Val accuracy: 0.56 Time taken: 58\n",
      "\n",
      "Epoch: 20 Training loss: 1.911 Training accuracy: 0.549 Val loss: 1.867 Val accuracy: 0.593 Time taken: 57\n",
      "\n",
      "Epoch: 21 Training loss: 1.903 Training accuracy: 0.558 Val loss: 1.868 Val accuracy: 0.592 Time taken: 58\n",
      "\n",
      "Epoch: 22 Training loss: 1.897 Training accuracy: 0.563 Val loss: 1.875 Val accuracy: 0.586 Time taken: 57\n",
      "\n",
      "Epoch: 23 Training loss: 1.927 Training accuracy: 0.534 Val loss: 1.945 Val accuracy: 0.515 Time taken: 57\n",
      "\n",
      "Epoch: 24 Training loss: 1.923 Training accuracy: 0.538 Val loss: 1.881 Val accuracy: 0.58 Time taken: 57\n",
      "\n",
      "Epoch: 25 Training loss: 1.934 Training accuracy: 0.526 Val loss: 1.926 Val accuracy: 0.534 Time taken: 57\n",
      "\n",
      "Epoch: 26 Training loss: 1.921 Training accuracy: 0.54 Val loss: 1.909 Val accuracy: 0.551 Time taken: 57\n",
      "\n",
      "Epoch: 27 Training loss: 1.948 Training accuracy: 0.513 Val loss: 1.944 Val accuracy: 0.517 Time taken: 57\n",
      "\n",
      "Epoch: 28 Training loss: 1.942 Training accuracy: 0.519 Val loss: 1.91 Val accuracy: 0.551 Time taken: 57\n",
      "\n",
      "Epoch: 29 Training loss: 1.943 Training accuracy: 0.518 Val loss: 1.959 Val accuracy: 0.502 Time taken: 57\n",
      "\n",
      "Epoch: 30 Training loss: 1.962 Training accuracy: 0.499 Val loss: 1.919 Val accuracy: 0.542 Time taken: 57\n",
      "Training losses: [2.166, 2.053, 2.009, 1.964, 1.947, 1.93, 1.907, 1.888, 1.887, 1.874, 1.866, 1.87, 1.858, 1.876, 1.863, 1.868, 1.875, 1.873, 1.894, 1.911, 1.903, 1.897, 1.927, 1.923, 1.934, 1.921, 1.948, 1.942, 1.943, 1.962]\n",
      "Training accuracies: [0.286, 0.402, 0.447, 0.492, 0.51, 0.528, 0.551, 0.57, 0.572, 0.585, 0.594, 0.589, 0.602, 0.584, 0.597, 0.592, 0.585, 0.587, 0.567, 0.549, 0.558, 0.563, 0.534, 0.538, 0.526, 0.54, 0.513, 0.519, 0.518, 0.499]\n",
      "Validation losses: [2.069, 2.014, 1.957, 1.933, 1.936, 1.923, 1.871, 1.862, 1.87, 1.849, 1.853, 1.858, 1.903, 1.869, 1.872, 1.884, 1.889, 1.841, 1.901, 1.867, 1.868, 1.875, 1.945, 1.881, 1.926, 1.909, 1.944, 1.91, 1.959, 1.919]\n",
      "Validation accuracies: [0.386, 0.441, 0.498, 0.525, 0.522, 0.536, 0.588, 0.596, 0.589, 0.609, 0.607, 0.602, 0.557, 0.592, 0.588, 0.576, 0.572, 0.619, 0.56, 0.593, 0.592, 0.586, 0.515, 0.58, 0.534, 0.551, 0.517, 0.551, 0.502, 0.542]\n"
     ]
    }
   ],
   "source": [
    "# Network: (Conv+Conv*+MaxPool)+(Conv+MaxPool)+(Conv+MaxPool)\n",
    "# Define the network, loss and optimizer\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(3,64,3,1,1)\n",
    "        self.c1a = nn.ReLU()\n",
    "        self.c2 = nn.Conv2d(64,128,3,1,1)\n",
    "        self.c2a = nn.ReLU()        \n",
    "        self.s1 = nn.MaxPool2d((2,2),2)\n",
    "        self.c3 = nn.Conv2d(128,128,3,1,1)\n",
    "        self.c3a = nn.ReLU()  \n",
    "        self.s2 = nn.MaxPool2d((2,2),2)\n",
    "        self.c4 = nn.Conv2d(128,128,3,1,1)\n",
    "        self.c4a = nn.ReLU()    \n",
    "        self.s3 = nn.MaxPool2d((2,2),2)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*128,1024)\n",
    "        self.fc1a = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1024,10)\n",
    "        self.fc2a = nn.Softmax(1)\n",
    "        \n",
    "        self.cnn_layers = [self.c1,self.c1a,self.c2,self.c2a,self.s1,self.c3,self.c3a,self.s2,\n",
    "                           self.c4,self.c4a,self.s3]\n",
    "        self.fc_layers = [self.fc1,self.fc1a,self.fc2,self.fc2a]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "# Test net mathematics\n",
    "with torch.no_grad():\n",
    "    temp_samples = temp_samples.to(device)\n",
    "    temp_output = net.forward(temp_samples)\n",
    "    print(temp_output.shape)\n",
    "print(net)\n",
    "# train the network\n",
    "epochs = 30\n",
    "train_accuracies=[]\n",
    "val_accuracies=[]\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    t1 = time.time() \n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    for index,(samples,labels) in enumerate(train_loader):\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net.forward(samples)\n",
    "        loss = criterion(outputs,labels)\n",
    "        preds = torch.argmax(outputs,1)\n",
    "        total_loss += loss\n",
    "        total_correct += torch.sum(preds == labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if index % 50==49:\n",
    "#             print('.',end='')\n",
    "    with torch.no_grad():\n",
    "        val_loss=0\n",
    "        val_correct=0\n",
    "        for samples,labels in val_loader:\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net.forward(samples)\n",
    "            loss = criterion(outputs,labels)\n",
    "            preds = torch.argmax(outputs,1)\n",
    "            val_loss += loss\n",
    "            val_correct += torch.sum(preds==labels)\n",
    "        print('\\nEpoch:',epoch+1,\n",
    "             'Training loss:',round(total_loss.item()*batch_size/len(train_ds),3),\n",
    "             'Training accuracy:',round(total_correct.item()/len(train_ds),3),\n",
    "             'Val loss:',round(val_loss.item()*batch_size/len(val_ds),3),\n",
    "             'Val accuracy:',round(val_correct.item()/len(val_ds),3),\n",
    "             'Time taken:',round(time.time()-t1))\n",
    "        train_accuracies.append(round(total_correct.item()/len(train_ds),3))\n",
    "        val_accuracies.append(round(val_correct.item()/len(val_ds),3))\n",
    "        train_losses.append(round(total_loss.item()*batch_size/len(train_ds),3))\n",
    "        val_losses.append(round(val_loss.item()*batch_size/len(val_ds),3))\n",
    "print(\"Training losses:\",train_losses)\n",
    "print(\"Training accuracies:\",train_accuracies)\n",
    "print(\"Validation losses:\",val_losses)\n",
    "print(\"Validation accuracies:\",val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "Net(\n",
      "  (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c1a): ReLU()\n",
      "  (s1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c2a): ReLU()\n",
      "  (c3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c3a): ReLU()\n",
      "  (s2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c4a): ReLU()\n",
      "  (s3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc1a): ReLU()\n",
      "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  (fc2a): Softmax()\n",
      ")\n",
      "\n",
      "Epoch: 1 Training loss: 2.177 Training accuracy: 0.276 Val loss: 2.088 Val accuracy: 0.366 Time taken: 31\n",
      "\n",
      "Epoch: 2 Training loss: 2.07 Training accuracy: 0.385 Val loss: 2.001 Val accuracy: 0.455 Time taken: 31\n",
      "\n",
      "Epoch: 3 Training loss: 2.021 Training accuracy: 0.434 Val loss: 2.01 Val accuracy: 0.446 Time taken: 31\n",
      "\n",
      "Epoch: 4 Training loss: 1.986 Training accuracy: 0.47 Val loss: 1.98 Val accuracy: 0.479 Time taken: 31\n",
      "\n",
      "Epoch: 5 Training loss: 1.962 Training accuracy: 0.495 Val loss: 1.939 Val accuracy: 0.518 Time taken: 31\n",
      "\n",
      "Epoch: 6 Training loss: 1.95 Training accuracy: 0.508 Val loss: 1.929 Val accuracy: 0.529 Time taken: 31\n",
      "\n",
      "Epoch: 7 Training loss: 1.932 Training accuracy: 0.526 Val loss: 1.924 Val accuracy: 0.535 Time taken: 31\n",
      "\n",
      "Epoch: 8 Training loss: 1.92 Training accuracy: 0.538 Val loss: 1.897 Val accuracy: 0.562 Time taken: 31\n",
      "\n",
      "Epoch: 9 Training loss: 1.905 Training accuracy: 0.554 Val loss: 1.885 Val accuracy: 0.572 Time taken: 31\n",
      "\n",
      "Epoch: 10 Training loss: 1.905 Training accuracy: 0.553 Val loss: 1.909 Val accuracy: 0.549 Time taken: 31\n",
      "\n",
      "Epoch: 11 Training loss: 1.902 Training accuracy: 0.556 Val loss: 1.867 Val accuracy: 0.593 Time taken: 31\n",
      "\n",
      "Epoch: 12 Training loss: 1.887 Training accuracy: 0.572 Val loss: 1.902 Val accuracy: 0.557 Time taken: 31\n",
      "\n",
      "Epoch: 13 Training loss: 1.89 Training accuracy: 0.569 Val loss: 1.861 Val accuracy: 0.597 Time taken: 31\n",
      "\n",
      "Epoch: 14 Training loss: 1.887 Training accuracy: 0.572 Val loss: 1.879 Val accuracy: 0.58 Time taken: 31\n",
      "\n",
      "Epoch: 15 Training loss: 1.877 Training accuracy: 0.583 Val loss: 1.862 Val accuracy: 0.598 Time taken: 31\n",
      "\n",
      "Epoch: 16 Training loss: 1.887 Training accuracy: 0.572 Val loss: 1.863 Val accuracy: 0.595 Time taken: 31\n",
      "\n",
      "Epoch: 17 Training loss: 1.875 Training accuracy: 0.584 Val loss: 1.89 Val accuracy: 0.569 Time taken: 31\n",
      "\n",
      "Epoch: 18 Training loss: 1.889 Training accuracy: 0.57 Val loss: 1.861 Val accuracy: 0.6 Time taken: 31\n",
      "\n",
      "Epoch: 19 Training loss: 1.889 Training accuracy: 0.571 Val loss: 1.927 Val accuracy: 0.533 Time taken: 31\n",
      "\n",
      "Epoch: 20 Training loss: 1.878 Training accuracy: 0.582 Val loss: 1.857 Val accuracy: 0.603 Time taken: 31\n",
      "\n",
      "Epoch: 21 Training loss: 1.891 Training accuracy: 0.569 Val loss: 1.869 Val accuracy: 0.592 Time taken: 31\n",
      "\n",
      "Epoch: 22 Training loss: 1.899 Training accuracy: 0.561 Val loss: 1.881 Val accuracy: 0.58 Time taken: 31\n",
      "\n",
      "Epoch: 23 Training loss: 1.926 Training accuracy: 0.535 Val loss: 1.904 Val accuracy: 0.556 Time taken: 31\n",
      "\n",
      "Epoch: 24 Training loss: 1.926 Training accuracy: 0.534 Val loss: 1.902 Val accuracy: 0.558 Time taken: 31\n",
      "\n",
      "Epoch: 25 Training loss: 1.923 Training accuracy: 0.538 Val loss: 1.915 Val accuracy: 0.546 Time taken: 31\n",
      "\n",
      "Epoch: 26 Training loss: 1.945 Training accuracy: 0.516 Val loss: 1.918 Val accuracy: 0.543 Time taken: 31\n",
      "\n",
      "Epoch: 27 Training loss: 1.929 Training accuracy: 0.531 Val loss: 1.893 Val accuracy: 0.568 Time taken: 31\n",
      "\n",
      "Epoch: 28 Training loss: 1.942 Training accuracy: 0.519 Val loss: 1.924 Val accuracy: 0.536 Time taken: 31\n",
      "\n",
      "Epoch: 29 Training loss: 1.941 Training accuracy: 0.52 Val loss: 1.967 Val accuracy: 0.494 Time taken: 31\n",
      "\n",
      "Epoch: 30 Training loss: 1.96 Training accuracy: 0.501 Val loss: 1.989 Val accuracy: 0.472 Time taken: 32\n",
      "Training losses: [2.177, 2.07, 2.021, 1.986, 1.962, 1.95, 1.932, 1.92, 1.905, 1.905, 1.902, 1.887, 1.89, 1.887, 1.877, 1.887, 1.875, 1.889, 1.889, 1.878, 1.891, 1.899, 1.926, 1.926, 1.923, 1.945, 1.929, 1.942, 1.941, 1.96]\n",
      "Training accuracies: [0.276, 0.385, 0.434, 0.47, 0.495, 0.508, 0.526, 0.538, 0.554, 0.553, 0.556, 0.572, 0.569, 0.572, 0.583, 0.572, 0.584, 0.57, 0.571, 0.582, 0.569, 0.561, 0.535, 0.534, 0.538, 0.516, 0.531, 0.519, 0.52, 0.501]\n",
      "Validation losses: [2.088, 2.001, 2.01, 1.98, 1.939, 1.929, 1.924, 1.897, 1.885, 1.909, 1.867, 1.902, 1.861, 1.879, 1.862, 1.863, 1.89, 1.861, 1.927, 1.857, 1.869, 1.881, 1.904, 1.902, 1.915, 1.918, 1.893, 1.924, 1.967, 1.989]\n",
      "Validation accuracies: [0.366, 0.455, 0.446, 0.479, 0.518, 0.529, 0.535, 0.562, 0.572, 0.549, 0.593, 0.557, 0.597, 0.58, 0.598, 0.595, 0.569, 0.6, 0.533, 0.603, 0.592, 0.58, 0.556, 0.558, 0.546, 0.543, 0.568, 0.536, 0.494, 0.472]\n"
     ]
    }
   ],
   "source": [
    "# Network: (Conv+MaxPool)+(Conv+Conv*+MaxPool)+(Conv+MaxPool)\n",
    "# Define the network, loss and optimizer\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(3,64,3,1,1)\n",
    "        self.c1a = nn.ReLU()\n",
    "        self.s1 = nn.MaxPool2d((2,2),2)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.c2a = nn.ReLU()        \n",
    "        self.c3 = nn.Conv2d(64,128,3,1,1)\n",
    "        self.c3a = nn.ReLU()  \n",
    "        self.s2 = nn.MaxPool2d((2,2),2)\n",
    "        self.c4 = nn.Conv2d(128,128,3,1,1)\n",
    "        self.c4a = nn.ReLU()    \n",
    "        self.s3 = nn.MaxPool2d((2,2),2)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*128,1024)\n",
    "        self.fc1a = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1024,10)\n",
    "        self.fc2a = nn.Softmax(1)\n",
    "        \n",
    "        self.cnn_layers = [self.c1,self.c1a,self.s1,self.c2,self.c2a,self.c3,self.c3a,self.s2,\n",
    "                           self.c4,self.c4a,self.s3]\n",
    "        self.fc_layers = [self.fc1,self.fc1a,self.fc2,self.fc2a]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "# Test net mathematics\n",
    "with torch.no_grad():\n",
    "    temp_samples = temp_samples.to(device)\n",
    "    temp_output = net.forward(temp_samples)\n",
    "    print(temp_output.shape)\n",
    "print(net)\n",
    "# train the network\n",
    "epochs = 30\n",
    "train_accuracies=[]\n",
    "val_accuracies=[]\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    t1 = time.time() \n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    for index,(samples,labels) in enumerate(train_loader):\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net.forward(samples)\n",
    "        loss = criterion(outputs,labels)\n",
    "        preds = torch.argmax(outputs,1)\n",
    "        total_loss += loss\n",
    "        total_correct += torch.sum(preds == labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if index % 50==49:\n",
    "#             print('.',end='')\n",
    "    with torch.no_grad():\n",
    "        val_loss=0\n",
    "        val_correct=0\n",
    "        for samples,labels in val_loader:\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net.forward(samples)\n",
    "            loss = criterion(outputs,labels)\n",
    "            preds = torch.argmax(outputs,1)\n",
    "            val_loss += loss\n",
    "            val_correct += torch.sum(preds==labels)\n",
    "        print('\\nEpoch:',epoch+1,\n",
    "             'Training loss:',round(total_loss.item()*batch_size/len(train_ds),3),\n",
    "             'Training accuracy:',round(total_correct.item()/len(train_ds),3),\n",
    "             'Val loss:',round(val_loss.item()*batch_size/len(val_ds),3),\n",
    "             'Val accuracy:',round(val_correct.item()/len(val_ds),3),\n",
    "             'Time taken:',round(time.time()-t1))\n",
    "        train_accuracies.append(round(total_correct.item()/len(train_ds),3))\n",
    "        val_accuracies.append(round(val_correct.item()/len(val_ds),3))\n",
    "        train_losses.append(round(total_loss.item()*batch_size/len(train_ds),3))\n",
    "        val_losses.append(round(val_loss.item()*batch_size/len(val_ds),3))\n",
    "print(\"Training losses:\",train_losses)\n",
    "print(\"Training accuracies:\",train_accuracies)\n",
    "print(\"Validation losses:\",val_losses)\n",
    "print(\"Validation accuracies:\",val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "Net(\n",
      "  (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c1a): ReLU()\n",
      "  (s1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c2a): ReLU()\n",
      "  (s2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c3a): ReLU()\n",
      "  (c4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c4a): ReLU()\n",
      "  (s3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc1a): ReLU()\n",
      "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  (fc2a): Softmax()\n",
      ")\n",
      "\n",
      "Epoch: 1 Training loss: 2.129 Training accuracy: 0.321 Val loss: 2.058 Val accuracy: 0.395 Time taken: 31\n",
      "\n",
      "Epoch: 2 Training loss: 2.032 Training accuracy: 0.423 Val loss: 1.987 Val accuracy: 0.467 Time taken: 31\n",
      "\n",
      "Epoch: 3 Training loss: 1.981 Training accuracy: 0.475 Val loss: 1.94 Val accuracy: 0.517 Time taken: 31\n",
      "\n",
      "Epoch: 4 Training loss: 1.961 Training accuracy: 0.497 Val loss: 1.942 Val accuracy: 0.515 Time taken: 31\n",
      "\n",
      "Epoch: 5 Training loss: 1.953 Training accuracy: 0.505 Val loss: 1.929 Val accuracy: 0.53 Time taken: 31\n",
      "\n",
      "Epoch: 6 Training loss: 1.935 Training accuracy: 0.523 Val loss: 1.912 Val accuracy: 0.547 Time taken: 31\n",
      "\n",
      "Epoch: 7 Training loss: 1.927 Training accuracy: 0.531 Val loss: 1.916 Val accuracy: 0.543 Time taken: 31\n",
      "\n",
      "Epoch: 8 Training loss: 1.923 Training accuracy: 0.536 Val loss: 1.934 Val accuracy: 0.524 Time taken: 31\n",
      "\n",
      "Epoch: 9 Training loss: 1.933 Training accuracy: 0.527 Val loss: 1.968 Val accuracy: 0.492 Time taken: 31\n",
      "\n",
      "Epoch: 10 Training loss: 1.94 Training accuracy: 0.52 Val loss: 1.893 Val accuracy: 0.568 Time taken: 31\n",
      "\n",
      "Epoch: 11 Training loss: 1.93 Training accuracy: 0.53 Val loss: 1.917 Val accuracy: 0.543 Time taken: 31\n",
      "\n",
      "Epoch: 12 Training loss: 1.946 Training accuracy: 0.514 Val loss: 1.926 Val accuracy: 0.534 Time taken: 31\n",
      "\n",
      "Epoch: 13 Training loss: 1.932 Training accuracy: 0.529 Val loss: 1.903 Val accuracy: 0.558 Time taken: 31\n",
      "\n",
      "Epoch: 14 Training loss: 1.953 Training accuracy: 0.507 Val loss: 1.988 Val accuracy: 0.472 Time taken: 31\n",
      "\n",
      "Epoch: 15 Training loss: 1.955 Training accuracy: 0.506 Val loss: 1.98 Val accuracy: 0.481 Time taken: 31\n",
      "\n",
      "Epoch: 16 Training loss: 1.995 Training accuracy: 0.466 Val loss: 1.994 Val accuracy: 0.467 Time taken: 31\n",
      "\n",
      "Epoch: 17 Training loss: 2.009 Training accuracy: 0.452 Val loss: 1.978 Val accuracy: 0.483 Time taken: 31\n",
      "\n",
      "Epoch: 18 Training loss: 2.014 Training accuracy: 0.447 Val loss: 2.054 Val accuracy: 0.407 Time taken: 31\n",
      "\n",
      "Epoch: 19 Training loss: 2.035 Training accuracy: 0.426 Val loss: 2.02 Val accuracy: 0.441 Time taken: 31\n",
      "\n",
      "Epoch: 20 Training loss: 2.051 Training accuracy: 0.41 Val loss: 2.07 Val accuracy: 0.391 Time taken: 31\n",
      "\n",
      "Epoch: 21 Training loss: 2.091 Training accuracy: 0.37 Val loss: 2.192 Val accuracy: 0.269 Time taken: 31\n",
      "\n",
      "Epoch: 22 Training loss: 2.2 Training accuracy: 0.261 Val loss: 2.081 Val accuracy: 0.38 Time taken: 31\n",
      "\n",
      "Epoch: 23 Training loss: 2.117 Training accuracy: 0.344 Val loss: 2.083 Val accuracy: 0.378 Time taken: 31\n",
      "\n",
      "Epoch: 24 Training loss: 2.111 Training accuracy: 0.35 Val loss: 2.078 Val accuracy: 0.383 Time taken: 31\n",
      "\n",
      "Epoch: 25 Training loss: 2.138 Training accuracy: 0.323 Val loss: 2.049 Val accuracy: 0.412 Time taken: 31\n",
      "\n",
      "Epoch: 26 Training loss: 2.065 Training accuracy: 0.396 Val loss: 2.136 Val accuracy: 0.326 Time taken: 31\n",
      "\n",
      "Epoch: 27 Training loss: 2.151 Training accuracy: 0.31 Val loss: 2.071 Val accuracy: 0.391 Time taken: 31\n",
      "\n",
      "Epoch: 28 Training loss: 2.104 Training accuracy: 0.357 Val loss: 2.263 Val accuracy: 0.199 Time taken: 31\n",
      "\n",
      "Epoch: 29 Training loss: 2.152 Training accuracy: 0.309 Val loss: 2.201 Val accuracy: 0.26 Time taken: 31\n",
      "\n",
      "Epoch: 30 Training loss: 2.194 Training accuracy: 0.267 Val loss: 2.138 Val accuracy: 0.323 Time taken: 31\n",
      "Training losses: [2.129, 2.032, 1.981, 1.961, 1.953, 1.935, 1.927, 1.923, 1.933, 1.94, 1.93, 1.946, 1.932, 1.953, 1.955, 1.995, 2.009, 2.014, 2.035, 2.051, 2.091, 2.2, 2.117, 2.111, 2.138, 2.065, 2.151, 2.104, 2.152, 2.194]\n",
      "Training accuracies: [0.321, 0.423, 0.475, 0.497, 0.505, 0.523, 0.531, 0.536, 0.527, 0.52, 0.53, 0.514, 0.529, 0.507, 0.506, 0.466, 0.452, 0.447, 0.426, 0.41, 0.37, 0.261, 0.344, 0.35, 0.323, 0.396, 0.31, 0.357, 0.309, 0.267]\n",
      "Validation losses: [2.058, 1.987, 1.94, 1.942, 1.929, 1.912, 1.916, 1.934, 1.968, 1.893, 1.917, 1.926, 1.903, 1.988, 1.98, 1.994, 1.978, 2.054, 2.02, 2.07, 2.192, 2.081, 2.083, 2.078, 2.049, 2.136, 2.071, 2.263, 2.201, 2.138]\n",
      "Validation accuracies: [0.395, 0.467, 0.517, 0.515, 0.53, 0.547, 0.543, 0.524, 0.492, 0.568, 0.543, 0.534, 0.558, 0.472, 0.481, 0.467, 0.483, 0.407, 0.441, 0.391, 0.269, 0.38, 0.378, 0.383, 0.412, 0.326, 0.391, 0.199, 0.26, 0.323]\n"
     ]
    }
   ],
   "source": [
    "# Network: (Conv+MaxPool)+(Conv+MaxPool)+(Conv+Conv*+MaxPool)\n",
    "# Define the network, loss and optimizer\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(3,64,3,1,1)\n",
    "        self.c1a = nn.ReLU()\n",
    "        self.s1 = nn.MaxPool2d((2,2),2)\n",
    "        self.c2 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.c2a = nn.ReLU()        \n",
    "        self.s2 = nn.MaxPool2d((2,2),2)\n",
    "        self.c3 = nn.Conv2d(64,64,3,1,1)\n",
    "        self.c3a = nn.ReLU()  \n",
    "        self.c4 = nn.Conv2d(64,128,3,1,1)\n",
    "        self.c4a = nn.ReLU()    \n",
    "        self.s3 = nn.MaxPool2d((2,2),2)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*128,1024)\n",
    "        self.fc1a = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1024,10)\n",
    "        self.fc2a = nn.Softmax(1)\n",
    "        \n",
    "        self.cnn_layers = [self.c1,self.c1a,self.s1,self.c2,self.c2a,self.s2,self.c3,self.c3a,\n",
    "                           self.c4,self.c4a,self.s3]\n",
    "        self.fc_layers = [self.fc1,self.fc1a,self.fc2,self.fc2a]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "# Test net mathematics\n",
    "with torch.no_grad():\n",
    "    temp_samples = temp_samples.to(device)\n",
    "    temp_output = net.forward(temp_samples)\n",
    "    print(temp_output.shape)\n",
    "print(net)\n",
    "# train the network\n",
    "epochs = 30\n",
    "train_accuracies=[]\n",
    "val_accuracies=[]\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    t1 = time.time() \n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    for index,(samples,labels) in enumerate(train_loader):\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net.forward(samples)\n",
    "        loss = criterion(outputs,labels)\n",
    "        preds = torch.argmax(outputs,1)\n",
    "        total_loss += loss\n",
    "        total_correct += torch.sum(preds == labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if index % 50==49:\n",
    "#             print('.',end='')\n",
    "    with torch.no_grad():\n",
    "        val_loss=0\n",
    "        val_correct=0\n",
    "        for samples,labels in val_loader:\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net.forward(samples)\n",
    "            loss = criterion(outputs,labels)\n",
    "            preds = torch.argmax(outputs,1)\n",
    "            val_loss += loss\n",
    "            val_correct += torch.sum(preds==labels)\n",
    "        print('\\nEpoch:',epoch+1,\n",
    "             'Training loss:',round(total_loss.item()*batch_size/len(train_ds),3),\n",
    "             'Training accuracy:',round(total_correct.item()/len(train_ds),3),\n",
    "             'Val loss:',round(val_loss.item()*batch_size/len(val_ds),3),\n",
    "             'Val accuracy:',round(val_correct.item()/len(val_ds),3),\n",
    "             'Time taken:',round(time.time()-t1))\n",
    "        train_accuracies.append(round(total_correct.item()/len(train_ds),3))\n",
    "        val_accuracies.append(round(val_correct.item()/len(val_ds),3))\n",
    "        train_losses.append(round(total_loss.item()*batch_size/len(train_ds),3))\n",
    "        val_losses.append(round(val_loss.item()*batch_size/len(val_ds),3))\n",
    "print(\"Training losses:\",train_losses)\n",
    "print(\"Training accuracies:\",train_accuracies)\n",
    "print(\"Validation losses:\",val_losses)\n",
    "print(\"Validation accuracies:\",val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "Net(\n",
      "  (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c1a): ReLU()\n",
      "  (s1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c2a): ReLU()\n",
      "  (s2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "  (fc1a): ReLU()\n",
      "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  (fc2a): Softmax()\n",
      ")\n",
      "\n",
      "Epoch: 1 Training loss: 2.075 Training accuracy: 0.379 Val loss: 1.967 Val accuracy: 0.492 Time taken: 31\n",
      "\n",
      "Epoch: 2 Training loss: 1.973 Training accuracy: 0.484 Val loss: 1.918 Val accuracy: 0.539 Time taken: 30\n",
      "\n",
      "Epoch: 3 Training loss: 1.929 Training accuracy: 0.528 Val loss: 1.905 Val accuracy: 0.553 Time taken: 30\n",
      "\n",
      "Epoch: 4 Training loss: 1.893 Training accuracy: 0.564 Val loss: 1.868 Val accuracy: 0.59 Time taken: 30\n",
      "\n",
      "Epoch: 5 Training loss: 1.868 Training accuracy: 0.589 Val loss: 1.836 Val accuracy: 0.621 Time taken: 30\n",
      "\n",
      "Epoch: 6 Training loss: 1.847 Training accuracy: 0.612 Val loss: 1.834 Val accuracy: 0.625 Time taken: 30\n",
      "\n",
      "Epoch: 7 Training loss: 1.828 Training accuracy: 0.63 Val loss: 1.814 Val accuracy: 0.644 Time taken: 30\n",
      "\n",
      "Epoch: 8 Training loss: 1.817 Training accuracy: 0.643 Val loss: 1.799 Val accuracy: 0.661 Time taken: 30\n",
      "\n",
      "Epoch: 9 Training loss: 1.805 Training accuracy: 0.653 Val loss: 1.784 Val accuracy: 0.674 Time taken: 30\n",
      "\n",
      "Epoch: 10 Training loss: 1.794 Training accuracy: 0.665 Val loss: 1.772 Val accuracy: 0.685 Time taken: 30\n",
      "\n",
      "Epoch: 11 Training loss: 1.783 Training accuracy: 0.676 Val loss: 1.767 Val accuracy: 0.693 Time taken: 30\n",
      "\n",
      "Epoch: 12 Training loss: 1.776 Training accuracy: 0.684 Val loss: 1.76 Val accuracy: 0.7 Time taken: 30\n",
      "\n",
      "Epoch: 13 Training loss: 1.768 Training accuracy: 0.691 Val loss: 1.753 Val accuracy: 0.706 Time taken: 30\n",
      "\n",
      "Epoch: 14 Training loss: 1.761 Training accuracy: 0.698 Val loss: 1.755 Val accuracy: 0.704 Time taken: 30\n",
      "\n",
      "Epoch: 15 Training loss: 1.753 Training accuracy: 0.707 Val loss: 1.754 Val accuracy: 0.706 Time taken: 30\n",
      "\n",
      "Epoch: 16 Training loss: 1.747 Training accuracy: 0.712 Val loss: 1.747 Val accuracy: 0.714 Time taken: 30\n",
      "\n",
      "Epoch: 17 Training loss: 1.742 Training accuracy: 0.718 Val loss: 1.74 Val accuracy: 0.72 Time taken: 30\n",
      "\n",
      "Epoch: 18 Training loss: 1.737 Training accuracy: 0.723 Val loss: 1.745 Val accuracy: 0.716 Time taken: 30\n",
      "\n",
      "Epoch: 19 Training loss: 1.733 Training accuracy: 0.727 Val loss: 1.729 Val accuracy: 0.731 Time taken: 30\n",
      "\n",
      "Epoch: 20 Training loss: 1.726 Training accuracy: 0.734 Val loss: 1.73 Val accuracy: 0.73 Time taken: 30\n",
      "\n",
      "Epoch: 21 Training loss: 1.726 Training accuracy: 0.733 Val loss: 1.736 Val accuracy: 0.722 Time taken: 30\n",
      "\n",
      "Epoch: 22 Training loss: 1.721 Training accuracy: 0.739 Val loss: 1.741 Val accuracy: 0.718 Time taken: 30\n",
      "\n",
      "Epoch: 23 Training loss: 1.716 Training accuracy: 0.744 Val loss: 1.736 Val accuracy: 0.724 Time taken: 30\n",
      "\n",
      "Epoch: 24 Training loss: 1.714 Training accuracy: 0.746 Val loss: 1.733 Val accuracy: 0.728 Time taken: 30\n",
      "\n",
      "Epoch: 25 Training loss: 1.714 Training accuracy: 0.745 Val loss: 1.739 Val accuracy: 0.721 Time taken: 30\n",
      "\n",
      "Epoch: 26 Training loss: 1.709 Training accuracy: 0.751 Val loss: 1.726 Val accuracy: 0.733 Time taken: 30\n",
      "\n",
      "Epoch: 27 Training loss: 1.71 Training accuracy: 0.75 Val loss: 1.727 Val accuracy: 0.732 Time taken: 30\n",
      "\n",
      "Epoch: 28 Training loss: 1.707 Training accuracy: 0.753 Val loss: 1.73 Val accuracy: 0.73 Time taken: 30\n",
      "\n",
      "Epoch: 29 Training loss: 1.703 Training accuracy: 0.757 Val loss: 1.731 Val accuracy: 0.729 Time taken: 30\n",
      "\n",
      "Epoch: 30 Training loss: 1.702 Training accuracy: 0.758 Val loss: 1.719 Val accuracy: 0.742 Time taken: 30\n",
      "Training losses: [2.075, 1.973, 1.929, 1.893, 1.868, 1.847, 1.828, 1.817, 1.805, 1.794, 1.783, 1.776, 1.768, 1.761, 1.753, 1.747, 1.742, 1.737, 1.733, 1.726, 1.726, 1.721, 1.716, 1.714, 1.714, 1.709, 1.71, 1.707, 1.703, 1.702]\n",
      "Training accuracies: [0.379, 0.484, 0.528, 0.564, 0.589, 0.612, 0.63, 0.643, 0.653, 0.665, 0.676, 0.684, 0.691, 0.698, 0.707, 0.712, 0.718, 0.723, 0.727, 0.734, 0.733, 0.739, 0.744, 0.746, 0.745, 0.751, 0.75, 0.753, 0.757, 0.758]\n",
      "Validation losses: [1.967, 1.918, 1.905, 1.868, 1.836, 1.834, 1.814, 1.799, 1.784, 1.772, 1.767, 1.76, 1.753, 1.755, 1.754, 1.747, 1.74, 1.745, 1.729, 1.73, 1.736, 1.741, 1.736, 1.733, 1.739, 1.726, 1.727, 1.73, 1.731, 1.719]\n",
      "Validation accuracies: [0.492, 0.539, 0.553, 0.59, 0.621, 0.625, 0.644, 0.661, 0.674, 0.685, 0.693, 0.7, 0.706, 0.704, 0.706, 0.714, 0.72, 0.716, 0.731, 0.73, 0.722, 0.718, 0.724, 0.728, 0.721, 0.733, 0.732, 0.73, 0.729, 0.742]\n"
     ]
    }
   ],
   "source": [
    "# Network: Conv+Pooling+Conv*+Pooling\n",
    "# Define the network, loss and optimizer\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(3,64,3,1,1)\n",
    "        self.c1a = nn.ReLU()\n",
    "        self.s1 = nn.MaxPool2d((2,2),2)\n",
    "        self.c2 = nn.Conv2d(64,128,3,1,1)\n",
    "        self.c2a = nn.ReLU()        \n",
    "        self.s2 = nn.MaxPool2d((2,2),2)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(8*8*128,1024)\n",
    "        self.fc1a = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1024,10)\n",
    "        self.fc2a = nn.Softmax(1)\n",
    "        \n",
    "        self.cnn_layers = [self.c1,self.c1a,self.s1,self.c2,self.c2a,self.s2]\n",
    "        self.fc_layers = [self.fc1,self.fc1a,self.fc2,self.fc2a]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "# Test net mathematics\n",
    "with torch.no_grad():\n",
    "    temp_samples = temp_samples.to(device)\n",
    "    temp_output = net.forward(temp_samples)\n",
    "    print(temp_output.shape)\n",
    "print(net)\n",
    "# train the network\n",
    "epochs = 30\n",
    "train_accuracies=[]\n",
    "val_accuracies=[]\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    t1 = time.time() \n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    for index,(samples,labels) in enumerate(train_loader):\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net.forward(samples)\n",
    "        loss = criterion(outputs,labels)\n",
    "        preds = torch.argmax(outputs,1)\n",
    "        total_loss += loss\n",
    "        total_correct += torch.sum(preds == labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if index % 50==49:\n",
    "#             print('.',end='')\n",
    "    with torch.no_grad():\n",
    "        val_loss=0\n",
    "        val_correct=0\n",
    "        for samples,labels in val_loader:\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net.forward(samples)\n",
    "            loss = criterion(outputs,labels)\n",
    "            preds = torch.argmax(outputs,1)\n",
    "            val_loss += loss\n",
    "            val_correct += torch.sum(preds==labels)\n",
    "        print('\\nEpoch:',epoch+1,\n",
    "             'Training loss:',round(total_loss.item()*batch_size/len(train_ds),3),\n",
    "             'Training accuracy:',round(total_correct.item()/len(train_ds),3),\n",
    "             'Val loss:',round(val_loss.item()*batch_size/len(val_ds),3),\n",
    "             'Val accuracy:',round(val_correct.item()/len(val_ds),3),\n",
    "             'Time taken:',round(time.time()-t1))\n",
    "        train_accuracies.append(round(total_correct.item()/len(train_ds),3))\n",
    "        val_accuracies.append(round(val_correct.item()/len(val_ds),3))\n",
    "        train_losses.append(round(total_loss.item()*batch_size/len(train_ds),3))\n",
    "        val_losses.append(round(val_loss.item()*batch_size/len(val_ds),3))\n",
    "print(\"Training losses:\",train_losses)\n",
    "print(\"Training accuracies:\",train_accuracies)\n",
    "print(\"Validation losses:\",val_losses)\n",
    "print(\"Validation accuracies:\",val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "Net(\n",
      "  (c1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (c1a): Tanh()\n",
      "  (s2): AvgPool2d(kernel_size=(2, 2), stride=2, padding=0)\n",
      "  (c3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (c3a): Tanh()\n",
      "  (s4): AvgPool2d(kernel_size=(2, 2), stride=2, padding=0)\n",
      "  (c5): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (c5a): Tanh()\n",
      "  (fc1): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc1a): Tanh()\n",
      "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (fc2a): Softmax()\n",
      ")\n",
      "\n",
      "Epoch: 1 Training loss: 2.144 Training accuracy: 0.313 Val loss: 2.094 Val accuracy: 0.362 Time taken: 30\n",
      "\n",
      "Epoch: 2 Training loss: 2.075 Training accuracy: 0.383 Val loss: 2.042 Val accuracy: 0.417 Time taken: 30\n",
      "\n",
      "Epoch: 3 Training loss: 2.042 Training accuracy: 0.417 Val loss: 2.018 Val accuracy: 0.44 Time taken: 30\n",
      "\n",
      "Epoch: 4 Training loss: 2.021 Training accuracy: 0.439 Val loss: 2.005 Val accuracy: 0.454 Time taken: 30\n",
      "\n",
      "Epoch: 5 Training loss: 2.004 Training accuracy: 0.456 Val loss: 1.997 Val accuracy: 0.463 Time taken: 30\n",
      "\n",
      "Epoch: 6 Training loss: 1.993 Training accuracy: 0.466 Val loss: 1.99 Val accuracy: 0.464 Time taken: 30\n",
      "\n",
      "Epoch: 7 Training loss: 1.979 Training accuracy: 0.482 Val loss: 1.976 Val accuracy: 0.485 Time taken: 31\n",
      "\n",
      "Epoch: 8 Training loss: 1.969 Training accuracy: 0.491 Val loss: 1.967 Val accuracy: 0.49 Time taken: 30\n",
      "\n",
      "Epoch: 9 Training loss: 1.962 Training accuracy: 0.497 Val loss: 1.975 Val accuracy: 0.483 Time taken: 30\n",
      "\n",
      "Epoch: 10 Training loss: 1.955 Training accuracy: 0.505 Val loss: 1.952 Val accuracy: 0.506 Time taken: 30\n",
      "\n",
      "Epoch: 11 Training loss: 1.949 Training accuracy: 0.511 Val loss: 1.956 Val accuracy: 0.504 Time taken: 30\n",
      "\n",
      "Epoch: 12 Training loss: 1.944 Training accuracy: 0.516 Val loss: 1.946 Val accuracy: 0.515 Time taken: 31\n",
      "\n",
      "Epoch: 13 Training loss: 1.937 Training accuracy: 0.524 Val loss: 1.943 Val accuracy: 0.516 Time taken: 30\n",
      "\n",
      "Epoch: 14 Training loss: 1.935 Training accuracy: 0.525 Val loss: 1.936 Val accuracy: 0.522 Time taken: 30\n",
      "\n",
      "Epoch: 15 Training loss: 1.929 Training accuracy: 0.53 Val loss: 1.934 Val accuracy: 0.524 Time taken: 30\n",
      "\n",
      "Epoch: 16 Training loss: 1.925 Training accuracy: 0.536 Val loss: 1.934 Val accuracy: 0.524 Time taken: 30\n",
      "\n",
      "Epoch: 17 Training loss: 1.919 Training accuracy: 0.54 Val loss: 1.925 Val accuracy: 0.533 Time taken: 30\n",
      "\n",
      "Epoch: 18 Training loss: 1.917 Training accuracy: 0.544 Val loss: 1.93 Val accuracy: 0.528 Time taken: 30\n",
      "\n",
      "Epoch: 19 Training loss: 1.913 Training accuracy: 0.546 Val loss: 1.923 Val accuracy: 0.538 Time taken: 30\n",
      "\n",
      "Epoch: 20 Training loss: 1.911 Training accuracy: 0.549 Val loss: 1.921 Val accuracy: 0.537 Time taken: 30\n",
      "\n",
      "Epoch: 21 Training loss: 1.905 Training accuracy: 0.555 Val loss: 1.916 Val accuracy: 0.543 Time taken: 30\n",
      "\n",
      "Epoch: 22 Training loss: 1.903 Training accuracy: 0.556 Val loss: 1.919 Val accuracy: 0.539 Time taken: 30\n",
      "\n",
      "Epoch: 23 Training loss: 1.9 Training accuracy: 0.56 Val loss: 1.913 Val accuracy: 0.546 Time taken: 30\n",
      "\n",
      "Epoch: 24 Training loss: 1.897 Training accuracy: 0.562 Val loss: 1.913 Val accuracy: 0.545 Time taken: 30\n",
      "\n",
      "Epoch: 25 Training loss: 1.897 Training accuracy: 0.563 Val loss: 1.911 Val accuracy: 0.548 Time taken: 30\n",
      "\n",
      "Epoch: 26 Training loss: 1.894 Training accuracy: 0.566 Val loss: 1.91 Val accuracy: 0.55 Time taken: 30\n",
      "\n",
      "Epoch: 27 Training loss: 1.89 Training accuracy: 0.57 Val loss: 1.909 Val accuracy: 0.547 Time taken: 30\n",
      "\n",
      "Epoch: 28 Training loss: 1.887 Training accuracy: 0.573 Val loss: 1.913 Val accuracy: 0.545 Time taken: 30\n",
      "\n",
      "Epoch: 29 Training loss: 1.886 Training accuracy: 0.575 Val loss: 1.909 Val accuracy: 0.552 Time taken: 30\n",
      "\n",
      "Epoch: 30 Training loss: 1.886 Training accuracy: 0.573 Val loss: 1.902 Val accuracy: 0.554 Time taken: 31\n",
      "Training losses: [2.144, 2.075, 2.042, 2.021, 2.004, 1.993, 1.979, 1.969, 1.962, 1.955, 1.949, 1.944, 1.937, 1.935, 1.929, 1.925, 1.919, 1.917, 1.913, 1.911, 1.905, 1.903, 1.9, 1.897, 1.897, 1.894, 1.89, 1.887, 1.886, 1.886]\n",
      "Training accuracies: [0.313, 0.383, 0.417, 0.439, 0.456, 0.466, 0.482, 0.491, 0.497, 0.505, 0.511, 0.516, 0.524, 0.525, 0.53, 0.536, 0.54, 0.544, 0.546, 0.549, 0.555, 0.556, 0.56, 0.562, 0.563, 0.566, 0.57, 0.573, 0.575, 0.573]\n",
      "Validation losses: [2.094, 2.042, 2.018, 2.005, 1.997, 1.99, 1.976, 1.967, 1.975, 1.952, 1.956, 1.946, 1.943, 1.936, 1.934, 1.934, 1.925, 1.93, 1.923, 1.921, 1.916, 1.919, 1.913, 1.913, 1.911, 1.91, 1.909, 1.913, 1.909, 1.902]\n",
      "Validation accuracies: [0.362, 0.417, 0.44, 0.454, 0.463, 0.464, 0.485, 0.49, 0.483, 0.506, 0.504, 0.515, 0.516, 0.522, 0.524, 0.524, 0.533, 0.528, 0.538, 0.537, 0.543, 0.539, 0.546, 0.545, 0.548, 0.55, 0.547, 0.545, 0.552, 0.554]\n"
     ]
    }
   ],
   "source": [
    "# Network: LeNet\n",
    "# Define the network, loss and optimizer\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(3,6,5,1,0)\n",
    "        self.c1a = nn.Tanh()\n",
    "        self.s2 = nn.AvgPool2d((2,2),2)\n",
    "        self.c3 = nn.Conv2d(6,16,5,1,0)\n",
    "        self.c3a = nn.Tanh()\n",
    "        self.s4 = nn.AvgPool2d((2,2),2)\n",
    "        self.c5 = nn.Conv2d(16,120,5,1,0)\n",
    "        self.c5a = nn.Tanh()\n",
    "\n",
    "        self.fc1 = nn.Linear(120,84)\n",
    "        self.fc1a = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(84,10)\n",
    "        self.fc2a = nn.Softmax(1)\n",
    "        \n",
    "        self.cnn_layers = [self.c1,self.c1a,self.s2,self.c3,self.c3a,self.s4,self.c5,self.c5a]\n",
    "        self.fc_layers = [self.fc1,self.fc1a,self.fc2,self.fc2a]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "# Test net mathematics\n",
    "with torch.no_grad():\n",
    "    temp_samples = temp_samples.to(device)\n",
    "    temp_output = net.forward(temp_samples)\n",
    "    print(temp_output.shape)\n",
    "print(net)\n",
    "# train the network\n",
    "epochs = 30\n",
    "train_accuracies=[]\n",
    "val_accuracies=[]\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    t1 = time.time() \n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    for index,(samples,labels) in enumerate(train_loader):\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net.forward(samples)\n",
    "        loss = criterion(outputs,labels)\n",
    "        preds = torch.argmax(outputs,1)\n",
    "        total_loss += loss\n",
    "        total_correct += torch.sum(preds == labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if index % 50==49:\n",
    "#             print('.',end='')\n",
    "    with torch.no_grad():\n",
    "        val_loss=0\n",
    "        val_correct=0\n",
    "        for samples,labels in val_loader:\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net.forward(samples)\n",
    "            loss = criterion(outputs,labels)\n",
    "            preds = torch.argmax(outputs,1)\n",
    "            val_loss += loss\n",
    "            val_correct += torch.sum(preds==labels)\n",
    "        print('\\nEpoch:',epoch+1,\n",
    "             'Training loss:',round(total_loss.item()*batch_size/len(train_ds),3),\n",
    "             'Training accuracy:',round(total_correct.item()/len(train_ds),3),\n",
    "             'Val loss:',round(val_loss.item()*batch_size/len(val_ds),3),\n",
    "             'Val accuracy:',round(val_correct.item()/len(val_ds),3),\n",
    "             'Time taken:',round(time.time()-t1))\n",
    "        train_accuracies.append(round(total_correct.item()/len(train_ds),3))\n",
    "        val_accuracies.append(round(val_correct.item()/len(val_ds),3))\n",
    "        train_losses.append(round(total_loss.item()*batch_size/len(train_ds),3))\n",
    "        val_losses.append(round(val_loss.item()*batch_size/len(val_ds),3))\n",
    "print(\"Training losses:\",train_losses)\n",
    "print(\"Training accuracies:\",train_accuracies)\n",
    "print(\"Validation losses:\",val_losses)\n",
    "print(\"Validation accuracies:\",val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "Net(\n",
      "  (c1): Conv2d(3, 16, kernel_size=(5, 5), stride=(2, 2))\n",
      "  (c1a): ReLU()\n",
      "  (s1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (n1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (c2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (c2a): ReLU()\n",
      "  (s2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (n2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc1a): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (fc2a): Softmax()\n",
      ")\n",
      "\n",
      "Epoch: 1 Training loss: 2.08 Training accuracy: 0.38 Val loss: 1.999 Val accuracy: 0.464 Time taken: 31\n",
      "\n",
      "Epoch: 2 Training loss: 1.987 Training accuracy: 0.472 Val loss: 1.957 Val accuracy: 0.504 Time taken: 31\n",
      "\n",
      "Epoch: 3 Training loss: 1.954 Training accuracy: 0.506 Val loss: 1.948 Val accuracy: 0.51 Time taken: 31\n",
      "\n",
      "Epoch: 4 Training loss: 1.932 Training accuracy: 0.526 Val loss: 1.914 Val accuracy: 0.544 Time taken: 30\n",
      "\n",
      "Epoch: 5 Training loss: 1.914 Training accuracy: 0.546 Val loss: 1.899 Val accuracy: 0.561 Time taken: 31\n",
      "\n",
      "Epoch: 6 Training loss: 1.903 Training accuracy: 0.556 Val loss: 1.889 Val accuracy: 0.568 Time taken: 30\n",
      "\n",
      "Epoch: 7 Training loss: 1.897 Training accuracy: 0.562 Val loss: 1.877 Val accuracy: 0.585 Time taken: 30\n",
      "\n",
      "Epoch: 8 Training loss: 1.888 Training accuracy: 0.572 Val loss: 1.877 Val accuracy: 0.582 Time taken: 30\n",
      "\n",
      "Epoch: 9 Training loss: 1.883 Training accuracy: 0.577 Val loss: 1.864 Val accuracy: 0.597 Time taken: 31\n",
      "\n",
      "Epoch: 10 Training loss: 1.876 Training accuracy: 0.584 Val loss: 1.856 Val accuracy: 0.604 Time taken: 30\n",
      "\n",
      "Epoch: 11 Training loss: 1.871 Training accuracy: 0.59 Val loss: 1.872 Val accuracy: 0.586 Time taken: 31\n",
      "\n",
      "Epoch: 12 Training loss: 1.87 Training accuracy: 0.59 Val loss: 1.854 Val accuracy: 0.606 Time taken: 31\n",
      "\n",
      "Epoch: 13 Training loss: 1.865 Training accuracy: 0.594 Val loss: 1.848 Val accuracy: 0.613 Time taken: 30\n",
      "\n",
      "Epoch: 14 Training loss: 1.86 Training accuracy: 0.599 Val loss: 1.846 Val accuracy: 0.614 Time taken: 31\n",
      "\n",
      "Epoch: 15 Training loss: 1.855 Training accuracy: 0.605 Val loss: 1.844 Val accuracy: 0.614 Time taken: 30\n",
      "\n",
      "Epoch: 16 Training loss: 1.853 Training accuracy: 0.606 Val loss: 1.846 Val accuracy: 0.615 Time taken: 30\n",
      "\n",
      "Epoch: 17 Training loss: 1.85 Training accuracy: 0.61 Val loss: 1.846 Val accuracy: 0.613 Time taken: 31\n",
      "\n",
      "Epoch: 18 Training loss: 1.849 Training accuracy: 0.611 Val loss: 1.835 Val accuracy: 0.624 Time taken: 31\n",
      "\n",
      "Epoch: 19 Training loss: 1.846 Training accuracy: 0.613 Val loss: 1.84 Val accuracy: 0.621 Time taken: 31\n",
      "\n",
      "Epoch: 20 Training loss: 1.843 Training accuracy: 0.616 Val loss: 1.831 Val accuracy: 0.627 Time taken: 31\n",
      "\n",
      "Epoch: 21 Training loss: 1.84 Training accuracy: 0.619 Val loss: 1.828 Val accuracy: 0.632 Time taken: 31\n",
      "\n",
      "Epoch: 22 Training loss: 1.839 Training accuracy: 0.62 Val loss: 1.839 Val accuracy: 0.619 Time taken: 31\n",
      "\n",
      "Epoch: 23 Training loss: 1.839 Training accuracy: 0.62 Val loss: 1.829 Val accuracy: 0.63 Time taken: 31\n",
      "\n",
      "Epoch: 24 Training loss: 1.837 Training accuracy: 0.623 Val loss: 1.822 Val accuracy: 0.64 Time taken: 31\n",
      "\n",
      "Epoch: 25 Training loss: 1.833 Training accuracy: 0.626 Val loss: 1.828 Val accuracy: 0.631 Time taken: 31\n",
      "\n",
      "Epoch: 26 Training loss: 1.831 Training accuracy: 0.628 Val loss: 1.823 Val accuracy: 0.637 Time taken: 30\n",
      "\n",
      "Epoch: 27 Training loss: 1.828 Training accuracy: 0.633 Val loss: 1.819 Val accuracy: 0.64 Time taken: 30\n",
      "\n",
      "Epoch: 28 Training loss: 1.827 Training accuracy: 0.632 Val loss: 1.816 Val accuracy: 0.641 Time taken: 31\n",
      "\n",
      "Epoch: 29 Training loss: 1.826 Training accuracy: 0.633 Val loss: 1.817 Val accuracy: 0.646 Time taken: 31\n",
      "\n",
      "Epoch: 30 Training loss: 1.825 Training accuracy: 0.634 Val loss: 1.822 Val accuracy: 0.638 Time taken: 31\n",
      "Training losses: [2.08, 1.987, 1.954, 1.932, 1.914, 1.903, 1.897, 1.888, 1.883, 1.876, 1.871, 1.87, 1.865, 1.86, 1.855, 1.853, 1.85, 1.849, 1.846, 1.843, 1.84, 1.839, 1.839, 1.837, 1.833, 1.831, 1.828, 1.827, 1.826, 1.825]\n",
      "Training accuracies: [0.38, 0.472, 0.506, 0.526, 0.546, 0.556, 0.562, 0.572, 0.577, 0.584, 0.59, 0.59, 0.594, 0.599, 0.605, 0.606, 0.61, 0.611, 0.613, 0.616, 0.619, 0.62, 0.62, 0.623, 0.626, 0.628, 0.633, 0.632, 0.633, 0.634]\n",
      "Validation losses: [1.999, 1.957, 1.948, 1.914, 1.899, 1.889, 1.877, 1.877, 1.864, 1.856, 1.872, 1.854, 1.848, 1.846, 1.844, 1.846, 1.846, 1.835, 1.84, 1.831, 1.828, 1.839, 1.829, 1.822, 1.828, 1.823, 1.819, 1.816, 1.817, 1.822]\n",
      "Validation accuracies: [0.464, 0.504, 0.51, 0.544, 0.561, 0.568, 0.585, 0.582, 0.597, 0.604, 0.586, 0.606, 0.613, 0.614, 0.614, 0.615, 0.613, 0.624, 0.621, 0.627, 0.632, 0.619, 0.63, 0.64, 0.631, 0.637, 0.64, 0.641, 0.646, 0.638]\n"
     ]
    }
   ],
   "source": [
    "# Network: Alexnet-like\n",
    "# Define the network, loss and optimizer\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(3,16,5,2,0)\n",
    "        self.c1a = nn.ReLU()\n",
    "        self.s1 = nn.MaxPool2d((2,2),2)\n",
    "        self.n1 = nn.BatchNorm2d(16)\n",
    "        self.c2 = nn.Conv2d(16,32,3,1,0)\n",
    "        self.c2a = nn.ReLU()\n",
    "        self.s2 = nn.MaxPool2d((2,2),2)\n",
    "        self.n2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.fc1 = nn.Linear(128,128)\n",
    "        self.fc1a = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128,10)\n",
    "        self.fc2a = nn.Softmax(1)\n",
    "        \n",
    "        self.cnn_layers = [self.c1,self.c1a,self.s1,self.n1,self.c2,self.c2a,self.s2,self.n2]\n",
    "        self.fc_layers = [self.fc1,self.fc1a,self.fc2,self.fc2a]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "# Test net mathematics\n",
    "with torch.no_grad():\n",
    "    temp_samples = temp_samples.to(device)\n",
    "    temp_output = net.forward(temp_samples)\n",
    "    print(temp_output.shape)\n",
    "print(net)\n",
    "# train the network\n",
    "epochs = 30\n",
    "train_accuracies=[]\n",
    "val_accuracies=[]\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    t1 = time.time() \n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    for index,(samples,labels) in enumerate(train_loader):\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net.forward(samples)\n",
    "        loss = criterion(outputs,labels)\n",
    "        preds = torch.argmax(outputs,1)\n",
    "        total_loss += loss\n",
    "        total_correct += torch.sum(preds == labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if index % 50==49:\n",
    "#             print('.',end='')\n",
    "    with torch.no_grad():\n",
    "        val_loss=0\n",
    "        val_correct=0\n",
    "        for samples,labels in val_loader:\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net.forward(samples)\n",
    "            loss = criterion(outputs,labels)\n",
    "            preds = torch.argmax(outputs,1)\n",
    "            val_loss += loss\n",
    "            val_correct += torch.sum(preds==labels)\n",
    "        print('\\nEpoch:',epoch+1,\n",
    "             'Training loss:',round(total_loss.item()*batch_size/len(train_ds),3),\n",
    "             'Training accuracy:',round(total_correct.item()/len(train_ds),3),\n",
    "             'Val loss:',round(val_loss.item()*batch_size/len(val_ds),3),\n",
    "             'Val accuracy:',round(val_correct.item()/len(val_ds),3),\n",
    "             'Time taken:',round(time.time()-t1))\n",
    "        train_accuracies.append(round(total_correct.item()/len(train_ds),3))\n",
    "        val_accuracies.append(round(val_correct.item()/len(val_ds),3))\n",
    "        train_losses.append(round(total_loss.item()*batch_size/len(train_ds),3))\n",
    "        val_losses.append(round(val_loss.item()*batch_size/len(val_ds),3))\n",
    "print(\"Training losses:\",train_losses)\n",
    "print(\"Training accuracies:\",train_accuracies)\n",
    "print(\"Validation losses:\",val_losses)\n",
    "print(\"Validation accuracies:\",val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "Net(\n",
      "  (c1): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c1a): ReLU()\n",
      "  (s1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (c2a): ReLU()\n",
      "  (s2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=16384, out_features=1024, bias=True)\n",
      "  (fc1a): ReLU()\n",
      "  (d1): Dropout(p=0.5)\n",
      "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  (fc2a): Softmax()\n",
      ")\n",
      "\n",
      "Epoch: 1 Training loss: 2.106 Training accuracy: 0.348 Val loss: 2.01 Val accuracy: 0.448 Time taken: 39\n",
      "\n",
      "Epoch: 2 Training loss: 2.007 Training accuracy: 0.448 Val loss: 1.97 Val accuracy: 0.486 Time taken: 39\n",
      "\n",
      "Epoch: 3 Training loss: 1.974 Training accuracy: 0.482 Val loss: 1.936 Val accuracy: 0.522 Time taken: 39\n",
      "\n",
      "Epoch: 4 Training loss: 1.951 Training accuracy: 0.507 Val loss: 1.915 Val accuracy: 0.543 Time taken: 39\n",
      "\n",
      "Epoch: 5 Training loss: 1.94 Training accuracy: 0.518 Val loss: 1.913 Val accuracy: 0.545 Time taken: 39\n"
     ]
    }
   ],
   "source": [
    "# Network: \n",
    "# Define the network, loss and optimizer\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(3,128,3,1,1)\n",
    "        self.c1a = nn.ReLU()\n",
    "        self.s1 = nn.MaxPool2d((2,2),2)\n",
    "        self.c2 = nn.Conv2d(128,256,3,1,1)\n",
    "        self.c2a = nn.ReLU()        \n",
    "        self.s2 = nn.MaxPool2d((2,2),2)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(8*8*256,1024)\n",
    "        self.fc1a = nn.ReLU()\n",
    "        self.d1 = nn.Dropout()\n",
    "        self.fc2 = nn.Linear(1024,10)\n",
    "        self.fc2a = nn.Softmax(1)\n",
    "        \n",
    "        self.cnn_layers = [self.c1,self.c1a,self.s1,self.c2,self.c2a,self.s2]\n",
    "        self.fc_layers = [self.fc1,self.fc1a,self.d1,self.fc2,self.fc2a]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.cnn_layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "# Test net mathematics\n",
    "with torch.no_grad():\n",
    "    temp_samples = temp_samples.to(device)\n",
    "    temp_output = net.forward(temp_samples)\n",
    "    print(temp_output.shape)\n",
    "print(net)\n",
    "# train the network\n",
    "epochs = 50\n",
    "train_accuracies=[]\n",
    "val_accuracies=[]\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    t1 = time.time() \n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    for index,(samples,labels) in enumerate(train_loader):\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net.forward(samples)\n",
    "        loss = criterion(outputs,labels)\n",
    "        preds = torch.argmax(outputs,1)\n",
    "        total_loss += loss\n",
    "        total_correct += torch.sum(preds == labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if index % 50==49:\n",
    "#             print('.',end='')\n",
    "    with torch.no_grad():\n",
    "        val_loss=0\n",
    "        val_correct=0\n",
    "        for samples,labels in val_loader:\n",
    "            samples = samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net.forward(samples)\n",
    "            loss = criterion(outputs,labels)\n",
    "            preds = torch.argmax(outputs,1)\n",
    "            val_loss += loss\n",
    "            val_correct += torch.sum(preds==labels)\n",
    "        print('\\nEpoch:',epoch+1,\n",
    "             'Training loss:',round(total_loss.item()*batch_size/len(train_ds),3),\n",
    "             'Training accuracy:',round(total_correct.item()/len(train_ds),3),\n",
    "             'Val loss:',round(val_loss.item()*batch_size/len(val_ds),3),\n",
    "             'Val accuracy:',round(val_correct.item()/len(val_ds),3),\n",
    "             'Time taken:',round(time.time()-t1))\n",
    "        train_accuracies.append(round(total_correct.item()/len(train_ds),3))\n",
    "        val_accuracies.append(round(val_correct.item()/len(val_ds),3))\n",
    "        train_losses.append(round(total_loss.item()*batch_size/len(train_ds),3))\n",
    "        val_losses.append(round(val_loss.item()*batch_size/len(val_ds),3))\n",
    "print(\"Training losses:\",train_losses)\n",
    "print(\"Training accuracies:\",train_accuracies)\n",
    "print(\"Validation losses:\",val_losses)\n",
    "print(\"Validation accuracies:\",val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
